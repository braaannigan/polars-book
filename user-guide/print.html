<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js ayu">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Polars - User Guide</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "ayu";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('ayu')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="quickstart/intro.html"><strong aria-hidden="true">2.</strong> Getting started</a></li><li class="chapter-item expanded "><a href="dsl/intro.html"><strong aria-hidden="true">3.</strong> Polars expressions</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="dsl/expressions.html"><strong aria-hidden="true">3.1.</strong> Expressions</a></li><li class="chapter-item "><a href="dsl/contexts.html"><strong aria-hidden="true">3.2.</strong> Contexts</a></li><li class="chapter-item "><a href="dsl/groupby.html"><strong aria-hidden="true">3.3.</strong> GroupBy</a></li><li class="chapter-item "><a href="dsl/folds.html"><strong aria-hidden="true">3.4.</strong> Folds</a></li><li class="chapter-item "><a href="dsl/window_functions.html"><strong aria-hidden="true">3.5.</strong> Window functions</a></li><li class="chapter-item "><a href="dsl/list_context.html"><strong aria-hidden="true">3.6.</strong> List context and row-wise compute</a></li><li class="chapter-item "><a href="dsl/numpy.html"><strong aria-hidden="true">3.7.</strong> Numpy universal functions</a></li><li class="chapter-item "><a href="dsl/custom_functions.html"><strong aria-hidden="true">3.8.</strong> Custom functions</a></li><li class="chapter-item "><a href="notebooks/introduction_polars.html"><strong aria-hidden="true">3.9.</strong> Examples</a></li><li class="chapter-item "><a href="dsl/api.html"><strong aria-hidden="true">3.10.</strong> API</a></li><li class="chapter-item "><a href="dsl/video_intro.html"><strong aria-hidden="true">3.11.</strong> Video introduction</a></li></ol></li><li class="chapter-item expanded "><a href="indexing.html"><strong aria-hidden="true">4.</strong> Indexing</a></li><li class="chapter-item expanded "><a href="datatypes.html"><strong aria-hidden="true">5.</strong> Data Types</a></li><li class="chapter-item expanded "><a href="coming_from_pandas.html"><strong aria-hidden="true">6.</strong> Coming from Pandas</a></li><li class="chapter-item expanded "><a href="coming_from_spark.html"><strong aria-hidden="true">7.</strong> Coming from Apache Spark</a></li><li class="chapter-item expanded "><a href="timeseries/intro.html"><strong aria-hidden="true">8.</strong> Time-series</a></li><li class="chapter-item expanded "><a href="howcani/intro.html"><strong aria-hidden="true">9.</strong> How can I?</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="howcani/io/intro.html"><strong aria-hidden="true">9.1.</strong> IO</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="howcani/io/csv.html"><strong aria-hidden="true">9.1.1.</strong> CSV files</a></li><li class="chapter-item "><a href="howcani/io/parquet.html"><strong aria-hidden="true">9.1.2.</strong> Parquet files</a></li><li class="chapter-item "><a href="multiple_files/intro.html"><strong aria-hidden="true">9.1.3.</strong> Multiple files</a></li><li class="chapter-item "><a href="howcani/io/read_db.html"><strong aria-hidden="true">9.1.4.</strong> Read from a database</a></li><li class="chapter-item "><a href="howcani/io/aws.html"><strong aria-hidden="true">9.1.5.</strong> Interact with AWS</a></li><li class="chapter-item "><a href="howcani/io/google-big-query.html"><strong aria-hidden="true">9.1.6.</strong> Interact with Google BigQuery</a></li><li class="chapter-item "><a href="howcani/io/postgres.html"><strong aria-hidden="true">9.1.7.</strong> Interact with Postgres</a></li><li class="chapter-item "><a href="howcani/interop/intro.html"><strong aria-hidden="true">9.1.8.</strong> Interoperability</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="howcani/interop/arrow.html"><strong aria-hidden="true">9.1.8.1.</strong> Arrow</a></li><li class="chapter-item "><a href="howcani/interop/numpy.html"><strong aria-hidden="true">9.1.8.2.</strong> NumPy</a></li></ol></li><li class="chapter-item "><a href="howcani/data/intro.html"><strong aria-hidden="true">9.1.9.</strong> Data handling</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="howcani/data/strings.html"><strong aria-hidden="true">9.1.9.1.</strong> Process strings</a></li><li class="chapter-item "><a href="howcani/data/timestamps.html"><strong aria-hidden="true">9.1.9.2.</strong> Process timestamps</a></li></ol></li></ol></li></ol></li><li class="chapter-item expanded "><a href="performance/intro.html"><strong aria-hidden="true">10.</strong> Performance</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="performance/strings.html"><strong aria-hidden="true">10.1.</strong> Strings</a></li></ol></li><li class="chapter-item expanded "><a href="optimizations/intro.html"><strong aria-hidden="true">11.</strong> Optimizations</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="optimizations/lazy/intro.html"><strong aria-hidden="true">11.1.</strong> Lazy API</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="optimizations/lazy/predicate-pushdown.html"><strong aria-hidden="true">11.1.1.</strong> Predicate pushdown</a></li><li class="chapter-item "><a href="optimizations/lazy/projection-pushdown.html"><strong aria-hidden="true">11.1.2.</strong> Projection pushdown</a></li><li class="chapter-item "><a href="optimizations/lazy/other-optimizations.html"><strong aria-hidden="true">11.1.3.</strong> Other optimizations</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="references.html"><strong aria-hidden="true">12.</strong> Reference guides</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu (default)</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Polars - User Guide</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div style="margin: 30px auto; background-color: white; border-radius: 50%; width: 200px; height: 200px;"><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars-logo-dark.svg" alt="Polars logo" style="width: 168px; height: 168px; padding: 10px 20px;"></div>
<h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>This book is an introduction to the
<a href="https://github.com/pola-rs/polars"><code>Polars</code> DataFrame library</a>. Its goal is to
introduce you to <code>Polars</code> by going through examples and comparing it to other
solutions. Some design choices are introduced here. The guide will also introduce you to
optimal usage of <code>Polars</code>.</p>
<p>Even though <code>Polars</code> is completely written in <a href="https://www.rust-lang.org/"><code>Rust</code></a> (no
runtime overhead!) and uses <a href="https://arrow.apache.org/"><code>Arrow</code></a> -- the
<a href="https://github.com/jorgecarleitao/arrow2">native arrow2 <code>Rust</code> implementation</a> -- as its foundation, the
examples presented in this guide will be mostly using its higher-level language
bindings. Higher-level bindings only serve as a thin wrapper for functionality implemented in the core library.</p>
<p>For <a href="https://pandas.pydata.org/"><code>Pandas</code></a> users, our
<a href="https://pypi.org/project/polars/">Python package</a> will offer the easiest way to get started with
<code>Polars</code>.</p>
<h2 id="goals-and-non-goals"><a class="header" href="#goals-and-non-goals">Goals and non-goals</a></h2>
<p>The goal of <code>Polars</code> is to provide a lightning fast <code>DataFrame</code> library that utilizes all
available cores on your machine. Unlike tools such as dask -- which tries to parallelize existing single-threaded libraries
like <code>NumPy</code> and <code>Pandas</code> -- <code>Polars</code> is written from the ground up, designed for parallelization of queries on <code>DataFrame</code>s.</p>
<p><code>Polars</code> goes to great lengths to:</p>
<ul>
<li>Reduce redundant copies</li>
<li>Traverse memory cache efficiently</li>
<li>Minimize contention in parallelism</li>
</ul>
<p><code>Polars</code> is lazy and semi-lazy. It allows you to do most of your work eagerly, similar to <code>Pandas</code>, but
it also provides a powerful expression syntax that will be optimized and executed on within the query engine.</p>
<p>In lazy <code>Polars</code> we are able to do query optimization on the entire query, further improving performance and memory pressure.</p>
<p><code>Polars</code> keeps track of your query in a <em>logical plan</em>. This
plan is optimized and reordered before running it. When a result is requested, <code>Polars</code>
distributes the available work to different <em>executors</em> that use the algorithms available
in the eager API to produce a result. Because the whole query context is known to
the optimizer and executors of the logical plan, processes dependent on separate data
sources can be parallelized on the fly.</p>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/api.svg" alt="" /></p>
<h3 id="performance-"><a class="header" href="#performance-">Performance 🚀🚀</a></h3>
<p>Polars is very fast, and in fact is one of the best performing solutions available.
See the results in h2oai's db-benchmark. The image below shows the biggest datasets yielding a result.</p>
<p><img src="https://www.ritchievink.com/img/post-35-polars-0.15/db-benchmark.png" alt="" /></p>
<h3 id="current-status"><a class="header" href="#current-status">Current status</a></h3>
<p>Below a concise list of the features allowing <code>Polars</code> to meet its goals:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Copy-on-write">Copy-on-write</a> (COW) semantics
<ul>
<li>&quot;Free&quot; clones</li>
<li>Cheap appends</li>
</ul>
</li>
<li>Appending without clones</li>
<li>Column oriented data storage
<ul>
<li>No block manager (i.e. predictable performance)</li>
</ul>
</li>
<li>Missing values indicated with bitmask
<ul>
<li>NaN are different from missing</li>
<li>Bitmask optimizations</li>
</ul>
</li>
<li>Efficient algorithms</li>
<li>Very fast IO
<ul>
<li>Its csv and parquet readers are among the fastest in existence</li>
</ul>
</li>
<li><a href="optimizations/lazy/intro.html">Query optimizations</a>
<ul>
<li>Predicate pushdown
<ul>
<li>Filtering at scan level</li>
</ul>
</li>
<li>Projection pushdown
<ul>
<li>Projection at scan level</li>
</ul>
</li>
<li>Aggregate pushdown
<ul>
<li>Aggregations at scan level</li>
</ul>
</li>
<li>Simplify expressions</li>
<li>Parallel execution of physical plan</li>
<li>Cardinality based groupby dispatch
<ul>
<li>Different groupby strategies based on data cardinality</li>
</ul>
</li>
</ul>
</li>
<li>SIMD vectorization</li>
<li><a href="https://numpy.org/doc/stable/reference/ufuncs.html"><code>NumPy</code> universal functions</a></li>
</ul>
<h2 id="acknowledgements"><a class="header" href="#acknowledgements">Acknowledgements</a></h2>
<p>Development of <code>Polars</code> is proudly powered by</p>
<p><a href="https://www.xomnia.com"><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/sponsors/xomnia.png" alt="Xomnia" /></a></p>
<h1 id="getting-started"><a class="header" href="#getting-started">Getting started</a></h1>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>Installing <code>Polars</code> is just a simple <code>pip install</code> away.</p>
<pre><code class="language-shell">$ pip install polars
</code></pre>
<p>All binaries are pre-built for <code>Python</code> v3.6+.</p>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick start</a></h2>
<p>Below we show a simple snippet that parses a CSV file, filters it, and finishes with a
groupby operation.</p>
<pre><code class="language-python">import polars as pl

df = pl.read_csv(&quot;https://j.mp/iriscsv&quot;)
print(df.filter(pl.col(&quot;sepal_length&quot;) &gt; 5)
      .groupby(&quot;species&quot;)
      .agg(pl.all().sum())
)
</code></pre>
<p>The snippet above will output:</p>
<pre><code class="language-text">shape: (3, 5)
╭──────────────┬──────────────────┬─────────────────┬──────────────────┬─────────────────╮
│ species      ┆ sepal_length_sum ┆ sepal_width_sum ┆ petal_length_sum ┆ petal_width_sum │
│ ---          ┆ ---              ┆ ---             ┆ ---              ┆ ---             │
│ str          ┆ f64              ┆ f64             ┆ f64              ┆ f64             │
╞══════════════╪══════════════════╪═════════════════╪══════════════════╪═════════════════╡
│ &quot;virginica&quot;  ┆ 324.5            ┆ 146.2           ┆ 273.1            ┆ 99.6            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ &quot;versicolor&quot; ┆ 281.9            ┆ 131.8           ┆ 202.9            ┆ 63.3            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ &quot;setosa&quot;     ┆ 116.9            ┆ 81.7            ┆ 33.2             ┆ 6.1             │
╰──────────────┴──────────────────┴─────────────────┴──────────────────┴─────────────────╯
</code></pre>
<p>As we can see, <code>Polars</code> pretty-prints the output object, including the column name and
datatype as headers.</p>
<h2 id="lazy-quick-start"><a class="header" href="#lazy-quick-start">Lazy quick start</a></h2>
<p>If we want to run this query in <code>lazy Polars</code> we'd write:</p>
<pre><code class="language-python">import polars as pl

print(
    pl.read_csv(&quot;https://j.mp/iriscsv&quot;)
    .lazy()
    .filter(pl.col(&quot;sepal_length&quot;) &gt; 5)
    .groupby(&quot;species&quot;)
    .agg(pl.all().sum())
    .collect()
)
</code></pre>
<p>When the data is stored locally, we can also use <code>scan_csv</code> to run the query in lazy polars.</p>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<p>If you want to dive right into the <code>Python</code> API docs, check the <a href="https://pola-rs.github.io/polars/py-polars/html/reference">the reference docs</a>.</p>
<h3 id="lazy-api"><a class="header" href="#lazy-api">Lazy API</a></h3>
<p>The lazy API builds a query plan. Nothing is executed until you explicitly ask <code>Polars</code>
to execute the query (via <code>LazyFrame.collect()</code>, or <code>LazyFrame.fetch()</code>). This provides
<code>Polars</code> with the entire context of the query, allowing optimizations and choosing the
fastest algorithm given that context.</p>
<p>Going from eager to lazy is often as simple as starting your query with <code>.lazy()</code> and ending with <code>.collect()</code>.</p>
<p>So the eager snippet above would become:</p>
<pre><code class="language-python">(
    df.lazy()
    .filter(pl.col(&quot;sepal_length&quot;) &gt; 5)
    .groupby(&quot;species&quot;)
    .agg(pl.all().sum())
    .collect()
)
</code></pre>
<h1 id="polars-expressions"><a class="header" href="#polars-expressions">Polars Expressions</a></h1>
<p><code>Polars</code> has a powerful concept called expressions. Polars expressions can be used in
various contexts and are a functional mapping of <code>Fn(Series) -&gt; Series</code>, meaning that they have a <code>Series</code> as an input and
a <code>Series</code> as an output. By looking at this functional definition, we can see that the output of an <code>Expr</code> also can serve
as the input of an <code>Expr</code>.</p>
<p>That may sound a bit strange, so let's start with an example.</p>
<h1 id="polars-expressions-1"><a class="header" href="#polars-expressions-1">Polars Expressions</a></h1>
<p>The following is an expression:</p>
<p><code>pl.col(&quot;foo&quot;).sort().head(2)</code></p>
<p>The snippet above says:</p>
<ol>
<li>Select column &quot;foo&quot;</li>
<li>Then sort the column</li>
<li>Then take the first two values of the sorted output</li>
</ol>
<p>The power of expressions is that every expression produces a new expression, and that they
can be <em>piped</em> together. You can run an expression by passing them to one of <code>Polars</code> execution contexts.</p>
<p>Here we run two expressions by running <code>df.select</code>:</p>
<pre><code class="language-python">df.select([
    pl.col(&quot;foo&quot;).sort().head(2),
    pl.col(&quot;bar&quot;).filter(pl.col(&quot;foo&quot;) == 1).sum()
])
</code></pre>
<p>All expressions are ran in parallel, meaning that separate <code>Polars</code> expressions are <strong>embarrassingly
parallel</strong>. Note that within an expression there may be more parallelization going on.</p>
<h2 id="expression-examples"><a class="header" href="#expression-examples">Expression examples</a></h2>
<p>In this section we will go through some examples, but first let's create a dataset:</p>
<pre><code class="language-python">import polars as pl
import numpy as np

np.random.seed(12)

df = pl.DataFrame(
    {
        &quot;nrs&quot;: [1, 2, 3, None, 5],
        &quot;names&quot;: [&quot;foo&quot;, &quot;ham&quot;, &quot;spam&quot;, &quot;egg&quot;, None],
        &quot;random&quot;: np.random.rand(5),
        &quot;groups&quot;: [&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;],
    }
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 4)
┌──────┬───────┬──────────┬────────┐
│ nrs  ┆ names ┆ random   ┆ groups │
│ ---  ┆ ---   ┆ ---      ┆ ---    │
│ i64  ┆ str   ┆ f64      ┆ str    │
╞══════╪═══════╪══════════╪════════╡
│ 1    ┆ foo   ┆ 0.154163 ┆ A      │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 2    ┆ ham   ┆ 0.74     ┆ A      │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 3    ┆ spam  ┆ 0.263315 ┆ B      │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ null ┆ egg   ┆ 0.533739 ┆ C      │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 5    ┆ null  ┆ 0.014575 ┆ B      │
└──────┴───────┴──────────┴────────┘
</code></pre>
<p>You can do a lot with expressions. They are so expressive that you sometimes have
multiple ways to get the same results. To get a better feel for them let's go through some
more examples.</p>
<h3 id="count-unique-values"><a class="header" href="#count-unique-values">Count unique values</a></h3>
<p>We can count the unique values in a column. Note that we are creating the same result in
different ways. To avoid duplicate column names in the <code>DataFrame</code>, we could use an
<code>alias</code> expression that can rename the expression.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.col(&quot;names&quot;).n_unique().alias(&quot;unique_names_1&quot;),
        pl.col(&quot;names&quot;).unique().count().alias(&quot;unique_names_2&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (1, 2)
┌────────────────┬────────────────┐
│ unique_names_1 ┆ unique_names_2 │
│ ---            ┆ ---            │
│ u32            ┆ u32            │
╞════════════════╪════════════════╡
│ 5              ┆ 5              │
└────────────────┴────────────────┘
</code></pre>
<h3 id="various-aggregations"><a class="header" href="#various-aggregations">Various aggregations</a></h3>
<p>We can do various aggregations. Below are examples of some of them, but there are more such as
<code>median</code>, <code>mean</code>, <code>first</code>, etc.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.sum(&quot;random&quot;).alias(&quot;sum&quot;),
        pl.min(&quot;random&quot;).alias(&quot;min&quot;),
        pl.max(&quot;random&quot;).alias(&quot;max&quot;),
        pl.col(&quot;random&quot;).max().alias(&quot;other_max&quot;),
        pl.std(&quot;random&quot;).alias(&quot;std dev&quot;),
        pl.var(&quot;random&quot;).alias(&quot;variance&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (1, 6)
┌──────────┬──────────┬──────┬───────────┬──────────┬──────────┐
│ sum      ┆ min      ┆ max  ┆ other_max ┆ std dev  ┆ variance │
│ ---      ┆ ---      ┆ ---  ┆ ---       ┆ ---      ┆ ---      │
│ f64      ┆ f64      ┆ f64  ┆ f64       ┆ f64      ┆ f64      │
╞══════════╪══════════╪══════╪═══════════╪══════════╪══════════╡
│ 1.705842 ┆ 0.014575 ┆ 0.74 ┆ 0.74      ┆ 0.293209 ┆ 0.085971 │
└──────────┴──────────┴──────┴───────────┴──────────┴──────────┘
</code></pre>
<h3 id="filter-and-conditionals"><a class="header" href="#filter-and-conditionals">Filter and conditionals</a></h3>
<p>We can also do some pretty complex things. In the next snippet we count all names ending
with the string <code>&quot;am&quot;</code>.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.col(&quot;names&quot;).filter(pl.col(&quot;names&quot;).str.contains(r&quot;am$&quot;)).count(),
    ]
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (1, 1)
┌───────┐
│ names │
│ ---   │
│ u32   │
╞═══════╡
│ 2     │
└───────┘
</code></pre>
<h3 id="binary-functions-and-modification"><a class="header" href="#binary-functions-and-modification">Binary functions and modification</a></h3>
<p>In the example below we use a conditional to create a new expression in the following
<code>when -&gt; then -&gt; otherwise</code> construct. The <code>when</code> function requires a predicate
expression (and thus leads to a boolean <code>Series</code>). The <code>then</code> function expects an
expression that will be used in case the predicate evaluates to <code>true</code>, and the <code>otherwise</code>
function expects an expression that will be used in case the predicate evaluates to <code>false</code>.</p>
<p>Note that you can pass any expression, or just base expressions like <code>pl.col(&quot;foo&quot;)</code>,
<code>pl.lit(3)</code>, <code>pl.lit(&quot;bar&quot;)</code>, etc.</p>
<p>Finally, we multiply this with the result of a <code>sum</code> expression:</p>
<pre><code class="language-python">out = df.select(
    [
        pl.when(pl.col(&quot;random&quot;) &gt; 0.5).then(0).otherwise(pl.col(&quot;random&quot;)) * pl.sum(&quot;nrs&quot;),
    ]
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 1)
┌──────────┐
│ literal  │
│ ---      │
│ f64      │
╞══════════╡
│ 1.695791 │
├╌╌╌╌╌╌╌╌╌╌┤
│ 0.0      │
├╌╌╌╌╌╌╌╌╌╌┤
│ 2.896465 │
├╌╌╌╌╌╌╌╌╌╌┤
│ 0.0      │
├╌╌╌╌╌╌╌╌╌╌┤
│ 0.160325 │
└──────────┘
</code></pre>
<h3 id="window-expressions"><a class="header" href="#window-expressions">Window expressions</a></h3>
<p>A polars expression can also do an implicit GROUPBY, AGGREGATION, and JOIN in a single expression.
In the examples below we do a GROUPBY OVER <code>&quot;groups&quot;</code> and AGGREGATE SUM of <code>&quot;random&quot;</code>, and in the next expression
we GROUPBY OVER <code>&quot;names&quot;</code> and AGGREGATE a LIST of <code>&quot;random&quot;</code>. These window functions can be combined with other expressions
and are an efficient way to determine group statistics. See more on those group statistics <a href="https://pola-rs.github.io/polars/py-polars/html/reference/expression.html#aggregation">here</a>.</p>
<pre><code class="language-python">df = df[
    [
        pl.col(&quot;*&quot;),  # select all
        pl.col(&quot;random&quot;).sum().over(&quot;groups&quot;).alias(&quot;sum[random]/groups&quot;),
        pl.col(&quot;random&quot;).list().over(&quot;names&quot;).alias(&quot;random/name&quot;),
    ]
]
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 6)
┌──────┬───────┬──────────┬────────┬────────────────────┬─────────────┐
│ nrs  ┆ names ┆ random   ┆ groups ┆ sum[random]/groups ┆ random/name │
│ ---  ┆ ---   ┆ ---      ┆ ---    ┆ ---                ┆ ---         │
│ i64  ┆ str   ┆ f64      ┆ str    ┆ f64                ┆ list [f64]  │
╞══════╪═══════╪══════════╪════════╪════════════════════╪═════════════╡
│ 1    ┆ foo   ┆ 0.154163 ┆ A      ┆ 0.894213           ┆ [0.154163]  │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2    ┆ ham   ┆ 0.74     ┆ A      ┆ 0.894213           ┆ [0.74]      │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 3    ┆ spam  ┆ 0.263315 ┆ B      ┆ 0.2778             ┆ [0.263315]  │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ null ┆ egg   ┆ 0.533739 ┆ C      ┆ 0.533739           ┆ [0.533739]  │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 5    ┆ null  ┆ 0.014575 ┆ B      ┆ 0.2778             ┆ [0.014575]  │
└──────┴───────┴──────────┴────────┴────────────────────┴─────────────┘
</code></pre>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>This is the tip of the iceberg in terms of possible expressions. There are a ton more, and they
can be combined in a variety ways.</p>
<p>This page was an introduction to <code>Polars</code> expressions, and gave a glimpse of what's
possible with them. In the next page we'll discuss in which contexts expressions can be used. Later in the guide we'll go through expressions in various groupby contexts, all while keeping <code>Polars</code> execution parallel.</p>
<h1 id="expression-contexts"><a class="header" href="#expression-contexts">Expression contexts</a></h1>
<p>You cannot use an expression anywhere. An expression needs a context, the available contexts are:</p>
<ul>
<li>selection: <code>df.select([..])</code></li>
<li>groupy aggregation: <code>df.groupby(..).agg([..])</code></li>
<li>hstack/ add columns: <code>df.with_columns([..])</code></li>
</ul>
<h2 id="syntactic-sugar"><a class="header" href="#syntactic-sugar">Syntactic sugar</a></h2>
<p>The reason for such a context, is that you actually are using the Polars lazy API, even if you use it in eager.
For instance this snippet:</p>
<pre><code class="language-python">df.groupby(&quot;foo&quot;).agg([pl.col(&quot;bar&quot;).sum()])
</code></pre>
<p>actually desugars to:</p>
<pre><code class="language-python">(df.lazy().groupby(&quot;foo&quot;).agg([pl.col(&quot;bar&quot;).sum()])).collect()
</code></pre>
<p>This allows Polars to push the expression into the query engine, do optimizations, and cache intermediate results.</p>
<h2 id="select-context"><a class="header" href="#select-context">Select context</a></h2>
<p>In the <code>select</code> context the selection applies expressions over columns. The expressions in this context must produce <code>Series</code> that are all
the same length or have a length of <code>1</code>.</p>
<p>A <code>Series</code> of a length of <code>1</code> will be broadcasted to match the height of the <code>DataFrame</code>.
Note that a <code>select</code> may produce new columns that are aggregations, combinations of expressions, or literals.</p>
<h4 id="selection-context"><a class="header" href="#selection-context">Selection context</a></h4>
<pre><code class="language-python">out = df.select(
    [
        pl.sum(&quot;nrs&quot;),
        pl.col(&quot;names&quot;).sort(),
        pl.col(&quot;names&quot;).first().alias(&quot;first name&quot;),
        (pl.mean(&quot;nrs&quot;) * 10).alias(&quot;10xnrs&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (5, 4)
┌─────┬───────┬────────────┬────────┐
│ nrs ┆ names ┆ first name ┆ 10xnrs │
│ --- ┆ ---   ┆ ---        ┆ ---    │
│ i64 ┆ str   ┆ str        ┆ f64    │
╞═════╪═══════╪════════════╪════════╡
│ 11  ┆ null  ┆ foo        ┆ 27.5   │
├╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 11  ┆ egg   ┆ foo        ┆ 27.5   │
├╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 11  ┆ foo   ┆ foo        ┆ 27.5   │
├╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 11  ┆ ham   ┆ foo        ┆ 27.5   │
├╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 11  ┆ spam  ┆ foo        ┆ 27.5   │
└─────┴───────┴────────────┴────────┘
</code></pre>
<p><strong>Add columns</strong></p>
<p>Adding columns to a <code>DataFrame</code> using <code>with_columns</code> is also the <code>selection</code> context.</p>
<pre><code class="language-python">df = df.with_columns(
    [
        pl.sum(&quot;nrs&quot;).alias(&quot;nrs_sum&quot;),
        pl.col(&quot;random&quot;).count().alias(&quot;count&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (5, 6)
┌──────┬───────┬──────────┬────────┬─────────┬───────┐
│ nrs  ┆ names ┆ random   ┆ groups ┆ nrs_sum ┆ count │
│ ---  ┆ ---   ┆ ---      ┆ ---    ┆ ---     ┆ ---   │
│ i64  ┆ str   ┆ f64      ┆ str    ┆ i64     ┆ u32   │
╞══════╪═══════╪══════════╪════════╪═════════╪═══════╡
│ 1    ┆ foo   ┆ 0.154163 ┆ A      ┆ 11      ┆ 5     │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ 2    ┆ ham   ┆ 0.74     ┆ A      ┆ 11      ┆ 5     │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ 3    ┆ spam  ┆ 0.263315 ┆ B      ┆ 11      ┆ 5     │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ null ┆ egg   ┆ 0.533739 ┆ C      ┆ 11      ┆ 5     │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ 5    ┆ null  ┆ 0.014575 ┆ B      ┆ 11      ┆ 5     │
└──────┴───────┴──────────┴────────┴─────────┴───────┘
</code></pre>
<h2 id="groupby-context"><a class="header" href="#groupby-context">Groupby context</a></h2>
<p>In the <code>groupby</code> context expressions work on groups and thus may yield results of any length (a group may have many members).</p>
<pre><code class="language-python">out = df.groupby(&quot;groups&quot;).agg(
    [
        pl.sum(&quot;nrs&quot;),  # sum nrs by groups
        pl.col(&quot;random&quot;).count().alias(&quot;count&quot;),  # count group members
        # sum random where name != null
        pl.col(&quot;random&quot;).filter(pl.col(&quot;names&quot;).is_not_null()).sum().suffix(&quot;_sum&quot;),
        pl.col(&quot;names&quot;).reverse().alias((&quot;reversed names&quot;)),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 5)
┌────────┬──────┬───────┬────────────┬────────────────┐
│ groups ┆ nrs  ┆ count ┆ random_sum ┆ reversed names │
│ ---    ┆ ---  ┆ ---   ┆ ---        ┆ ---            │
│ str    ┆ i64  ┆ u32   ┆ f64        ┆ list [str]     │
╞════════╪══════╪═══════╪════════════╪════════════════╡
│ C      ┆ null ┆ 1     ┆ 0.533739   ┆ [&quot;egg&quot;]        │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ A      ┆ 3    ┆ 2     ┆ 0.894213   ┆ [&quot;ham&quot;, &quot;foo&quot;] │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ B      ┆ 8    ┆ 2     ┆ 0.263315   ┆ [null, &quot;spam&quot;] │
└────────┴──────┴───────┴────────────┴────────────────┘
</code></pre>
<p>Besides the standard <code>groupby</code>, <code>groupby_dynamic</code>, and <code>groupby_rolling</code> are also entrances to the <code>groupby context</code>.</p>
<h1 id="groupby"><a class="header" href="#groupby">GroupBy</a></h1>
<blockquote>
<p>The GroupBy page is under construction.</p>
</blockquote>
<h2 id="a-multithreaded-approach"><a class="header" href="#a-multithreaded-approach">A multithreaded approach</a></h2>
<p>One of the most efficient ways to process tabular data is to parallelize its processing
via the &quot;split-apply-combine&quot; approach. This operation is at the core of the <code>Polars</code>
grouping implementation, allowing it to attain lightning-fast operations. Specifically, both the &quot;split&quot; and &quot;apply&quot; phases are executed in a multi-threaded
fashion.</p>
<p>A simple grouping operation is taken below as an example to illustrate this approach:</p>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/split-apply-combine.svg" alt="" /></p>
<p>For the hashing operations performed during the &quot;split&quot; phase, <code>Polars</code> uses a
multithreaded lock-free approach that is illustrated on the following schema:</p>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/lock-free-hash.svg" alt="" /></p>
<p>This parallelization allows the grouping and joining operations (for instance) to be
blazingly fast!</p>
<blockquote>
<p>Check out <a href="https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/">this blog post</a>
for more details.</p>
</blockquote>
<h2 id="do-not-kill-the-parallelization"><a class="header" href="#do-not-kill-the-parallelization">Do not kill the parallelization!</a></h2>
<p>We have all heard that <code>Python</code> is slow, and does &quot;not scale.&quot; Besides the overhead of
running &quot;slow&quot; bytecode, <code>Python</code> has to remain within the constraints of the Global
Interpreter Lock (GIL). This means that if you were to use a <code>lambda</code> or a custom <code>Python</code>
function to apply during a parallelized phase, <code>Polars</code> speed is capped running <code>Python</code>
code preventing any multiple threads from executing the function.</p>
<p>This all feels terribly limiting, especially because we often need those <code>lambda</code> functions in a
<code>.groupby()</code> step, for example. This approach is still supported by <code>Polars</code>, but
keeping in mind bytecode <strong>and</strong> the GIL costs have to be paid.</p>
<p>To mitigate this, <code>Polars</code> implements a powerful syntax defined not only in its lazy API,
but also in its eager API.</p>
<h2 id="polars-expressions-2"><a class="header" href="#polars-expressions-2">Polars Expressions</a></h2>
<p>In the introduction on the previous page we discussed that using custom Python functions,
killed parallelization, and that we can use the expressions of the lazy API to mitigate
this. Let's take a look at what that means.</p>
<p>We can start with the simple
<a href="https://github.com/unitedstates/congress-legislators">US congress dataset</a>.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset

q = (
    dataset.lazy()
    .groupby(&quot;first_name&quot;)
    .agg(
        [
            pl.count(),
            pl.col(&quot;gender&quot;).list(),
            pl.first(&quot;last_name&quot;),
        ]
    )
    .sort(&quot;count&quot;, reverse=True)
    .limit(5)
)

df = q.collect()
</code></pre>
<h4 id="basic-aggregations"><a class="header" href="#basic-aggregations">Basic aggregations</a></h4>
<p>You can easily combine different aggregations by adding multiple expressions in a
<code>list</code>. There is no upper bound on the number of aggregations you can do, and you can
make any combination you want. In the snippet below we do the following aggregations:</p>
<p>Per GROUP <code>&quot;first_name&quot;</code> we</p>
<ul>
<li>count the number of rows in the group:
<ul>
<li>short form: <code>pl.count(&quot;party&quot;)</code></li>
<li>full form: <code>pl.col(&quot;party&quot;).count()</code></li>
</ul>
</li>
<li>aggregate the gender values groups to a list:
<ul>
<li>full form: <code>pl.col(&quot;gender&quot;).list()</code></li>
</ul>
</li>
<li>get the first value of column <code>&quot;last_name&quot;</code> in the group:
<ul>
<li>short form: <code>pl.first(&quot;last_name&quot;)</code></li>
<li>full form: <code>pl.col(&quot;last_name&quot;).first()</code></li>
</ul>
</li>
</ul>
<p>Besides the aggregation, we immediately sort the result and limit to the top <code>5</code> so that
we have a nice summary overview.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset

q = (
    dataset.lazy()
    .groupby(&quot;first_name&quot;)
    .agg(
        [
            pl.count(),
            pl.col(&quot;gender&quot;).list(),
            pl.first(&quot;last_name&quot;),
        ]
    )
    .sort(&quot;count&quot;, reverse=True)
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 4)
┌────────────┬───────┬─────────────────────┬───────────┐
│ first_name ┆ count ┆ gender              ┆ last_name │
│ ---        ┆ ---   ┆ ---                 ┆ ---       │
│ cat        ┆ u32   ┆ list [cat]          ┆ str       │
╞════════════╪═══════╪═════════════════════╪═══════════╡
│ John       ┆ 1254  ┆ [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] ┆ Walker    │
├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ William    ┆ 1022  ┆ [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] ┆ Few       │
├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ James      ┆ 712   ┆ [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] ┆ Armstrong │
├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ Thomas     ┆ 453   ┆ [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] ┆ Tucker    │
├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ Charles    ┆ 439   ┆ [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] ┆ Carroll   │
└────────────┴───────┴─────────────────────┴───────────┘
</code></pre>
<h4 id="conditionals"><a class="header" href="#conditionals">Conditionals</a></h4>
<p>It's that easy! Let's turn it up a notch. Let's say we want to know how
many delegates of a &quot;state&quot; are &quot;Pro&quot; or &quot;Anti&quot; administration. We could directly query
that in the aggregation without the need of <code>lambda</code> or grooming the <code>DataFrame</code>.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset

q = (
    dataset.lazy()
    .groupby(&quot;state&quot;)
    .agg(
        [
            (pl.col(&quot;party&quot;) == &quot;Anti-Administration&quot;).sum().alias(&quot;anti&quot;),
            (pl.col(&quot;party&quot;) == &quot;Pro-Administration&quot;).sum().alias(&quot;pro&quot;),
        ]
    )
    .sort(&quot;pro&quot;, reverse=True)
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 3)
┌───────┬──────┬─────┐
│ state ┆ anti ┆ pro │
│ ---   ┆ ---  ┆ --- │
│ cat   ┆ u32  ┆ u32 │
╞═══════╪══════╪═════╡
│ CT    ┆ 0    ┆ 3   │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┤
│ NJ    ┆ 0    ┆ 3   │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┤
│ NC    ┆ 1    ┆ 2   │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┤
│ SC    ┆ 0    ┆ 1   │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┤
│ PA    ┆ 1    ┆ 1   │
└───────┴──────┴─────┘
</code></pre>
<p>Similarly,  this could also be done with a nested GROUPBY, but that doesn't help show off some of these nice features. 😉</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset

q = (
    dataset.lazy()
    .groupby([&quot;state&quot;, &quot;party&quot;])
    .agg([pl.count(&quot;party&quot;).alias(&quot;count&quot;)])
    .filter((pl.col(&quot;party&quot;) == &quot;Anti-Administration&quot;) | (pl.col(&quot;party&quot;) == &quot;Pro-Administration&quot;))
    .sort(&quot;count&quot;, reverse=True)
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 3)
┌───────┬─────────────────────┬───────┐
│ state ┆ party               ┆ count │
│ ---   ┆ ---                 ┆ ---   │
│ cat   ┆ cat                 ┆ u32   │
╞═══════╪═════════════════════╪═══════╡
│ CT    ┆ Pro-Administration  ┆ 3     │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ NJ    ┆ Pro-Administration  ┆ 3     │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ VA    ┆ Anti-Administration ┆ 3     │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ NC    ┆ Pro-Administration  ┆ 2     │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ PA    ┆ Pro-Administration  ┆ 1     │
└───────┴─────────────────────┴───────┘
</code></pre>
<h4 id="filtering"><a class="header" href="#filtering">Filtering</a></h4>
<p>We can also filter the groups. Let's say we want to compute a mean per group, but we
don't want to include all values from that group, and we also don't want to filter the
rows from the <code>DataFrame</code> (because we need those rows for another aggregation).</p>
<p>In the example below we show how that can be done. Note that we can make <code>Python</code>
functions for clarity. These functions don't cost us anything. That is because we only
create <code>Polars</code> expressions, we don't apply a custom function over a <code>Series</code> during
runtime of the query.</p>
<pre><code class="language-python">from datetime import date

import polars as pl

from .dataset import dataset


def compute_age() -&gt; pl.Expr:
    return date(2021, 1, 1).year - pl.col(&quot;birthday&quot;).dt.year()


def avg_birthday(gender: str) -&gt; pl.Expr:
    return compute_age().filter(pl.col(&quot;gender&quot;) == gender).mean().alias(f&quot;avg {gender} birthday&quot;)


q = (
    dataset.lazy()
    .groupby([&quot;state&quot;])
    .agg(
        [
            avg_birthday(&quot;M&quot;),
            avg_birthday(&quot;F&quot;),
            (pl.col(&quot;gender&quot;) == &quot;M&quot;).sum().alias(&quot;# male&quot;),
            (pl.col(&quot;gender&quot;) == &quot;F&quot;).sum().alias(&quot;# female&quot;),
        ]
    )
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 5)
┌───────┬────────────────┬────────────────┬────────┬──────────┐
│ state ┆ avg M birthday ┆ avg F birthday ┆ # male ┆ # female │
│ ---   ┆ ---            ┆ ---            ┆ ---    ┆ ---      │
│ cat   ┆ f64            ┆ f64            ┆ u32    ┆ u32      │
╞═══════╪════════════════╪════════════════╪════════╪══════════╡
│ CO    ┆ 130.8876       ┆ 72.666667      ┆ 89     ┆ 3        │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤
│ PR    ┆ 113.0          ┆ null           ┆ 19     ┆ 0        │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤
│ NM    ┆ 138.980769     ┆ 69.8           ┆ 52     ┆ 5        │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤
│ WY    ┆ 137.717949     ┆ 75.0           ┆ 39     ┆ 1        │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤
│ CT    ┆ 189.508621     ┆ 97.333333      ┆ 234    ┆ 6        │
└───────┴────────────────┴────────────────┴────────┴──────────┘
</code></pre>
<h4 id="sorting"><a class="header" href="#sorting">Sorting</a></h4>
<p>It's common to see a <code>DataFrame</code> being sorted for the sole purpose of managing the ordering during a
GROUPBY operation. Let's say that we want to get the names of the oldest and youngest politicians per state. We could SORT and GROUPBY.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset


def get_person() -&gt; pl.Expr:
    return pl.col(&quot;first_name&quot;) + pl.lit(&quot; &quot;) + pl.col(&quot;last_name&quot;)


q = (
    dataset.lazy()
    .sort(&quot;birthday&quot;)
    .groupby([&quot;state&quot;])
    .agg(
        [
            get_person().first().alias(&quot;youngest&quot;),
            get_person().last().alias(&quot;oldest&quot;),
        ]
    )
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 3)
┌───────┬────────────────────┬──────────────────┐
│ state ┆ youngest           ┆ oldest           │
│ ---   ┆ ---                ┆ ---              │
│ cat   ┆ str                ┆ str              │
╞═══════╪════════════════════╪══════════════════╡
│ GU    ┆ Antonio Won Pat    ┆ Robert Underwood │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ UT    ┆ John Bernhisel     ┆ Mia Love         │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ WA    ┆ Columbia Lancaster ┆ Randy Tate       │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ FL    ┆ Charles Downing    ┆ Patrick Murphy   │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ AR    ┆ Archibald Yell     ┆ Tim Griffin      │
└───────┴────────────────────┴──────────────────┘
</code></pre>
<p>However, <strong>if</strong> we also want to sort the names alphabetically, this
breaks. Luckily we can sort in a <code>groupby</code> context separate from the <code>DataFrame</code>.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset


def get_person() -&gt; pl.Expr:
    return pl.col(&quot;first_name&quot;) + pl.lit(&quot; &quot;) + pl.col(&quot;last_name&quot;)


q = (
    dataset.lazy()
    .sort(&quot;birthday&quot;)
    .groupby([&quot;state&quot;])
    .agg(
        [
            get_person().first().alias(&quot;youngest&quot;),
            get_person().last().alias(&quot;oldest&quot;),
            get_person().sort().first().alias(&quot;alphabetical_first&quot;),
        ]
    )
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 4)
┌───────┬────────────────┬──────────────────────┬─────────────────────────┐
│ state ┆ youngest       ┆ oldest               ┆ alphabetical_first      │
│ ---   ┆ ---            ┆ ---                  ┆ ---                     │
│ cat   ┆ str            ┆ str                  ┆ str                     │
╞═══════╪════════════════╪══════════════════════╪═════════════════════════╡
│ TX    ┆ John Cranford  ┆ Will Hurd            ┆ Abraham Kazen           │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ CO    ┆ Allen Bradford ┆ Jared Polis          ┆ Allen Bradford          │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ NM    ┆ José Gallegos  ┆ Xochitl Torres Small ┆ Albert Fall             │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ PI    ┆ Pablo Ocampo   ┆ Carlos Romulo        ┆ Benito Legarda Y Tuason │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ DE    ┆ Samuel White   ┆ John Carney          ┆ Albert Polk             │
└───────┴────────────────┴──────────────────────┴─────────────────────────┘
</code></pre>
<p>We can even sort by another column in the <code>groupby</code> context. If we want to know if the
alphabetically sorted name is male or female we could add:
<code>pl.col(&quot;gender&quot;).sort_by(&quot;first_name&quot;).first().alias(&quot;gender&quot;)</code></p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset


def get_person() -&gt; pl.Expr:
    return pl.col(&quot;first_name&quot;) + pl.lit(&quot; &quot;) + pl.col(&quot;last_name&quot;)


q = (
    dataset.lazy()
    .sort(&quot;birthday&quot;)
    .groupby([&quot;state&quot;])
    .agg(
        [
            get_person().first().alias(&quot;youngest&quot;),
            get_person().last().alias(&quot;oldest&quot;),
            get_person().sort().first().alias(&quot;alphabetical_first&quot;),
            pl.col(&quot;gender&quot;).sort_by(&quot;first_name&quot;).first().alias(&quot;gender&quot;),
        ]
    )
    .sort(&quot;state&quot;)
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 5)
┌───────┬───────────────────┬────────────────┬────────────────────┬────────┐
│ state ┆ youngest          ┆ oldest         ┆ alphabetical_first ┆ gender │
│ ---   ┆ ---               ┆ ---            ┆ ---                ┆ ---    │
│ cat   ┆ str               ┆ str            ┆ str                ┆ cat    │
╞═══════╪═══════════════════╪════════════════╪════════════════════╪════════╡
│ DE    ┆ Samuel White      ┆ John Carney    ┆ Albert Polk        ┆ M      │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ VA    ┆ William Grayson   ┆ Scott Taylor   ┆ Abraham Venable    ┆ M      │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ SC    ┆ Ralph Izard       ┆ Joe Cunningham ┆ Abraham Nott       ┆ M      │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ MD    ┆ Benjamin Contee   ┆ Frank Kratovil ┆ Albert Blakeney    ┆ M      │
├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ PA    ┆ Thomas Fitzsimons ┆ Ryan Costello  ┆ Aaron Kreider      ┆ M      │
└───────┴───────────────────┴────────────────┴────────────────────┴────────┘
</code></pre>
<h3 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h3>
<p>In the examples above we've seen that we can do a lot by combining expressions. By doing
so we delay the use of custom <code>Python</code> functions that slow down the queries (by the slow
nature of Python AND the GIL).</p>
<p>If we are missing a type expression let us know by opening a
<a href="https://github.com/pola-rs/polars/issues/new/choose">feature request</a>!</p>
<h1 id="folds"><a class="header" href="#folds">Folds</a></h1>
<p><code>Polars</code> provides expressions/methods for horizontal aggregations like <a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.sum.html"><code>sum</code></a>,
<a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.min.html"><code>min</code></a>, <a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.mean.html"><code>mean</code></a>,
etc. by setting the argument <code>axis=1</code>. However, when you need a more complex aggregation the default methods provided by the
<code>Polars</code> library may not be sufficient. That's when <code>folds</code> come in handy.</p>
<p>The <code>Polars</code> <code>fold</code> expression operates on columns for maximum speed. It utilizes the data layout very efficiently and often has vectorized execution.</p>
<p>Let's start with an example by implementing the <code>sum</code> operation ourselves, with a <code>fold</code>.</p>
<h2 id="manual-sum"><a class="header" href="#manual-sum">Manual Sum</a></h2>
<pre><code class="language-python">    {
        &quot;a&quot;: [1, 2, 3],
        &quot;b&quot;: [10, 20, 30],
    }
)

out = df.select(
    pl.fold(acc=pl.lit(0), f=lambda acc, x: acc + x, exprs=pl.col(&quot;*&quot;)).alias(&quot;sum&quot;),
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 1)
┌─────┐
│ sum │
│ --- │
│ i64 │
╞═════╡
│ 11  │
├╌╌╌╌╌┤
│ 22  │
├╌╌╌╌╌┤
│ 33  │
└─────┘
</code></pre>
<p>The snippet above recursively applies the function <code>f(acc, x) -&gt; acc</code> to an accumulator <code>acc</code> and a new column <code>x</code>.
The function operates on columns individually and can take advantage of cache efficiency and vectorization.</p>
<h2 id="conditional"><a class="header" href="#conditional">Conditional</a></h2>
<p>In the case where you'd want to apply a condition/predicate on all columns in a <code>DataFrame</code> a <code>fold</code> operation can be
a very concise way to express this.</p>
<pre><code class="language-python">    {
        &quot;a&quot;: [1, 2, 3],
        &quot;b&quot;: [0, 1, 2],
    }
)

out = df.filter(
    pl.fold(
        acc=pl.lit(True),
        f=lambda acc, x: acc &amp; x,
        exprs=pl.col(&quot;*&quot;) &gt; 1,
    )
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (1, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 3   ┆ 2   │
└─────┴─────┘
</code></pre>
<p>In the snippet we filter all rows where <strong>each</strong> column value is <code>&gt;</code> <code>1</code>.</p>
<h2 id="folds-and-string-data"><a class="header" href="#folds-and-string-data">Folds and string data</a></h2>
<p>Folds could be used to concatenate string data. However, due to the materialization of intermediate columns, this
operation will have squared complexity.</p>
<p>Therefore, we recommend using the <code>concat_str</code> expression for this.</p>
<pre><code class="language-python">df = pl.DataFrame(
    {
        &quot;a&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;],
        &quot;b&quot;: [1, 2, 3],
    }
)

out = df.select(
    [
        pl.concat_str([&quot;a&quot;, &quot;b&quot;]),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 1)
┌─────┐
│ a   │
│ --- │
│ str │
╞═════╡
│ a1  │
├╌╌╌╌╌┤
│ b2  │
├╌╌╌╌╌┤
│ c3  │
└─────┘
</code></pre>
<h1 id="window-functions-"><a class="header" href="#window-functions-">Window functions 🚀🚀</a></h1>
<p>Window functions are expressions with superpowers. They allow you to perform aggregations on groups in the
<code>select</code> context. Let's get a feel of what that means. First we create a dataset. The dataset loaded in the
snippet below contains information about pokemon and has the following columns:</p>
<p><code>['#',  'Name',  'Type 1',  'Type 2',  'Total',  'HP',  'Attack',  'Defense',  'Sp. Atk',  'Sp. Def',  'Speed',  'Generation',  'Legendary']</code></p>
<pre><code class="language-python">import polars as pl

# then let's load some csv data with information about pokemon
df = pl.read_csv(
    &quot;https://gist.githubusercontent.com/ritchie46/cac6b337ea52281aa23c049250a4ff03/raw/89a957ff3919d90e6ef2d34235e6bf22304f3366/pokemon.csv&quot;
)
</code></pre>
<pre><code class="language-text">shape: (163, 13)
┌─────┬───────────────────────┬─────────┬────────┬─────┬─────────┬───────┬────────────┬───────────┐
│ #   ┆ Name                  ┆ Type 1  ┆ Type 2 ┆ ... ┆ Sp. Def ┆ Speed ┆ Generation ┆ Legendary │
│ --- ┆ ---                   ┆ ---     ┆ ---    ┆     ┆ ---     ┆ ---   ┆ ---        ┆ ---       │
│ i64 ┆ str                   ┆ str     ┆ str    ┆     ┆ i64     ┆ i64   ┆ i64        ┆ bool      │
╞═════╪═══════════════════════╪═════════╪════════╪═════╪═════════╪═══════╪════════════╪═══════════╡
│ 1   ┆ Bulbasaur             ┆ Grass   ┆ Poison ┆ ... ┆ 65      ┆ 45    ┆ 1          ┆ false     │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ 2   ┆ Ivysaur               ┆ Grass   ┆ Poison ┆ ... ┆ 80      ┆ 60    ┆ 1          ┆ false     │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ 3   ┆ Venusaur              ┆ Grass   ┆ Poison ┆ ... ┆ 100     ┆ 80    ┆ 1          ┆ false     │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ 3   ┆ VenusaurMega Venusaur ┆ Grass   ┆ Poison ┆ ... ┆ 120     ┆ 80    ┆ 1          ┆ false     │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ ... ┆ ...                   ┆ ...     ┆ ...    ┆ ... ┆ ...     ┆ ...   ┆ ...        ┆ ...       │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ 147 ┆ Dratini               ┆ Dragon  ┆ null   ┆ ... ┆ 50      ┆ 50    ┆ 1          ┆ false     │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ 148 ┆ Dragonair             ┆ Dragon  ┆ null   ┆ ... ┆ 70      ┆ 70    ┆ 1          ┆ false     │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ 149 ┆ Dragonite             ┆ Dragon  ┆ Flying ┆ ... ┆ 100     ┆ 80    ┆ 1          ┆ false     │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ 150 ┆ Mewtwo                ┆ Psychic ┆ null   ┆ ... ┆ 90      ┆ 130   ┆ 1          ┆ true      │
└─────┴───────────────────────┴─────────┴────────┴─────┴─────────┴───────┴────────────┴───────────┘
</code></pre>
<h2 id="groupby-aggregations-in-selection"><a class="header" href="#groupby-aggregations-in-selection">Groupby Aggregations in selection</a></h2>
<p>Below we show how to use window functions to group over different columns and perform an aggregation on them.
Doing so allows us to use multiple groupby operations in parallel, using a single query. The results of the aggregation
are projected back to the original rows. Therefore, a window function will always lead to a <code>DataFrame</code> with the same size
as the original.</p>
<p>Note how we call <code>.over(&quot;Type 1&quot;)</code> and <code>.over([&quot;Type 1&quot;, &quot;Type 2&quot;])</code>. Using window functions we can aggregate
over different groups in a single <code>select</code> call!</p>
<p>The best part is, this won't cost you anything. The computed groups are cached and shared between different <code>window</code> expressions.</p>
<pre><code class="language-python">
out = df.select(
    [
        &quot;Type 1&quot;,
        &quot;Type 2&quot;,
        pl.col(&quot;Attack&quot;).mean().over(&quot;Type 1&quot;).alias(&quot;avg_attack_by_type&quot;),
        pl.col(&quot;Defense&quot;).mean().over([&quot;Type 1&quot;, &quot;Type 2&quot;]).alias(&quot;avg_defense_by_type_combination&quot;),
        pl.col(&quot;Attack&quot;).mean().alias(&quot;avg_attack&quot;),
    ]
)
</code></pre>
<pre><code class="language-text">shape: (163, 5)
┌─────────┬────────┬────────────────────┬─────────────────────────────────┬────────────┐
│ Type 1  ┆ Type 2 ┆ avg_attack_by_type ┆ avg_defense_by_type_combination ┆ avg_attack │
│ ---     ┆ ---    ┆ ---                ┆ ---                             ┆ ---        │
│ str     ┆ str    ┆ f64                ┆ f64                             ┆ f64        │
╞═════════╪════════╪════════════════════╪═════════════════════════════════╪════════════╡
│ Grass   ┆ Poison ┆ 72.923077          ┆ 67.8                            ┆ 75.349693  │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Grass   ┆ Poison ┆ 72.923077          ┆ 67.8                            ┆ 75.349693  │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Grass   ┆ Poison ┆ 72.923077          ┆ 67.8                            ┆ 75.349693  │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Grass   ┆ Poison ┆ 72.923077          ┆ 67.8                            ┆ 75.349693  │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ ...     ┆ ...    ┆ ...                ┆ ...                             ┆ ...        │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Dragon  ┆ null   ┆ 94.0               ┆ 55.0                            ┆ 75.349693  │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Dragon  ┆ null   ┆ 94.0               ┆ 55.0                            ┆ 75.349693  │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Dragon  ┆ Flying ┆ 94.0               ┆ 95.0                            ┆ 75.349693  │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Psychic ┆ null   ┆ 53.875             ┆ 51.428571                       ┆ 75.349693  │
└─────────┴────────┴────────────────────┴─────────────────────────────────┴────────────┘
</code></pre>
<h2 id="operations-per-group"><a class="header" href="#operations-per-group">Operations per group</a></h2>
<p>Window functions can do more than aggregation. They can also be viewed as an operation within a group. If, for instance, you
want to <code>sort</code> the values within a <code>group</code>, you can write <code>col(&quot;value&quot;).sort().over(&quot;group&quot;)</code> and voilà! We sorted by group!</p>
<p>Let's filter out some rows to make this more clear.</p>
<pre><code class="language-python">filtered = df.filter(pl.col(&quot;Type 2&quot;) == &quot;Psychic&quot;).select(
    [
        &quot;Name&quot;,
        &quot;Type 1&quot;,
        &quot;Speed&quot;,
    ]
)
print(filtered)
</code></pre>
<pre><code class="language-text">shape: (7, 3)
┌─────────────────────┬────────┬───────┐
│ Name                ┆ Type 1 ┆ Speed │
│ ---                 ┆ ---    ┆ ---   │
│ str                 ┆ str    ┆ i64   │
╞═════════════════════╪════════╪═══════╡
│ Slowpoke            ┆ Water  ┆ 15    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Slowbro             ┆ Water  ┆ 30    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ SlowbroMega Slowbro ┆ Water  ┆ 30    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Exeggcute           ┆ Grass  ┆ 40    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Exeggutor           ┆ Grass  ┆ 55    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Starmie             ┆ Water  ┆ 115   │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Jynx                ┆ Ice    ┆ 95    │
└─────────────────────┴────────┴───────┘
</code></pre>
<p>Observe that the group <code>Water</code> of column <code>Type 1</code> is not contiguous. There are two rows of <code>Grass</code> in between. Also note
that each pokemon within a group are sorted by <code>Speed</code> in <code>ascending</code> order. Unfortunately, for this example we want them sorted in
<code>descending</code> speed order. Luckily with window functions this is easy to accomplish.</p>
<pre><code class="language-python">out = filtered.with_columns(
    [
        pl.col([&quot;Name&quot;, &quot;Speed&quot;]).sort(reverse=True).over(&quot;Type 1&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">
shape: (7, 3)
┌─────────────────────┬────────┬───────┐
│ Name                ┆ Type 1 ┆ Speed │
│ ---                 ┆ ---    ┆ ---   │
│ str                 ┆ str    ┆ i64   │
╞═════════════════════╪════════╪═══════╡
│ Starmie             ┆ Water  ┆ 115   │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Slowpoke            ┆ Water  ┆ 30    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ SlowbroMega Slowbro ┆ Water  ┆ 30    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Exeggutor           ┆ Grass  ┆ 55    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Exeggcute           ┆ Grass  ┆ 40    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Slowbro             ┆ Water  ┆ 15    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ Jynx                ┆ Ice    ┆ 95    │
└─────────────────────┴────────┴───────┘
</code></pre>
<p><code>Polars</code> keeps track of each group's location and maps the expressions to the proper row locations. This will also work
over different groups in a single <code>select</code>.</p>
<p>The power of window expressions is that you often don't need a <code>groupby -&gt; explode</code> combination, but you can put the logic in a
single expression. It also makes the API cleaner. If properly used a:</p>
<ul>
<li><code>groupby</code> -&gt; marks that groups are aggregated and we expect a <code>DataFrame</code> of size <code>n_groups</code></li>
<li><code>over</code> -&gt; marks that we want to compute something within a group, but doesn't modify the original size of the <code>DataFrame</code></li>
</ul>
<h2 id="window-expression-rules"><a class="header" href="#window-expression-rules">Window expression rules</a></h2>
<p>The evaluations of window expressions are as follows (assuming we apply it to a <code>pl.Int32</code> column):</p>
<pre><code class="language-python"># aggregate and broadcast within a group
# output type: -&gt; Int32
pl.sum(&quot;foo&quot;).over(&quot;groups&quot;)

# sum within a group and multiply with group elements
# output type: -&gt; Int32
(pl.col(&quot;x&quot;).sum() * pl.col(&quot;y&quot;)).over(&quot;groups&quot;)

# sum within a group and multiply with group elements 
# and aggregate the group to a list
# output type: -&gt; List(Int32)
(pl.col(&quot;x&quot;).sum() * pl.col(&quot;y&quot;)).list().over(&quot;groups&quot;)

# note that it will require an explicit `list()` call
# sum within a group and multiply with group elements 
# and aggregate the group to a list
# the flatten call explodes that list

# This is the fastest method to do things over groups when the groups are sorted
(pl.col(&quot;x&quot;).sum() * pl.col(&quot;y&quot;)).list().over(&quot;groups&quot;).flatten()
</code></pre>
<h2 id="more-examples"><a class="header" href="#more-examples">More examples</a></h2>
<p>For more exercise, below are some window functions for us to compute:</p>
<ul>
<li>sort all pokemon by type</li>
<li>select the first <code>3</code> pokemon per type as <code>&quot;Type 1&quot;</code></li>
<li>sort the pokemon within a type by speed and select the first <code>3</code> as <code>&quot;fastest/group&quot;</code></li>
<li>sort the pokemon within a type by attack and select the first <code>3</code> as <code>&quot;strongest/group&quot;</code></li>
<li>sort the pokemon by name within a type and select the first <code>3</code> as <code>&quot;sorted_by_alphabet&quot;</code></li>
</ul>
<pre><code class="language-python">
out = df.sort(&quot;Type 1&quot;).select(
    [
        pl.col(&quot;Type 1&quot;).head(3).list().over(&quot;Type 1&quot;).flatten(),
        pl.col(&quot;Name&quot;).sort_by(pl.col(&quot;Speed&quot;)).head(3).list().over(&quot;Type 1&quot;).flatten().alias(&quot;fastest/group&quot;),
        pl.col(&quot;Name&quot;).sort_by(pl.col(&quot;Attack&quot;)).head(3).list().over(&quot;Type 1&quot;).flatten().alias(&quot;strongest/group&quot;),
        pl.col(&quot;Name&quot;).sort().head(3).list().over(&quot;Type 1&quot;).flatten().alias(&quot;sorted_by_alphabet&quot;),
    ]
)
</code></pre>
<pre><code class="language-text">shape: (43, 4)
┌────────┬─────────────────────┬─────────────────┬─────────────────────────┐
│ Type 1 ┆ fastest/group       ┆ strongest/group ┆ sorted_by_alphabet      │
│ ---    ┆ ---                 ┆ ---             ┆ ---                     │
│ str    ┆ str                 ┆ str             ┆ str                     │
╞════════╪═════════════════════╪═════════════════╪═════════════════════════╡
│ Bug    ┆ Paras               ┆ Metapod         ┆ Beedrill                │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Bug    ┆ Metapod             ┆ Kakuna          ┆ BeedrillMega Beedrill   │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Bug    ┆ Parasect            ┆ Caterpie        ┆ Butterfree              │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Dragon ┆ Dratini             ┆ Dratini         ┆ Dragonair               │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ ...    ┆ ...                 ┆ ...             ┆ ...                     │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Rock   ┆ Omanyte             ┆ Omastar         ┆ Geodude                 │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Water  ┆ Slowpoke            ┆ Magikarp        ┆ Blastoise               │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Water  ┆ Slowbro             ┆ Tentacool       ┆ BlastoiseMega Blastoise │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ Water  ┆ SlowbroMega Slowbro ┆ Horsea          ┆ Cloyster                │
└────────┴─────────────────────┴─────────────────┴─────────────────────────┘
</code></pre>
<h2 id="flattened-window-function"><a class="header" href="#flattened-window-function">Flattened window function</a></h2>
<p>If we have a window function that aggregates to a <code>list</code> like the example above with the following expression:</p>
<p><code>pl.col(&quot;Name&quot;).sort_by(pl.col(&quot;Speed&quot;)).head(3).list().over(&quot;Type 1&quot;)</code></p>
<p>This still works, but that
would give us a column type <code>List</code> which might not be what we want (this would significantly increase our memory usage!).</p>
<p>Instead we could <code>flatten</code>. This just turns our 2D list into a 1D array and projects that array/column back to our <code>DataFrame</code>.
This is very fast because the reshape is often free, and adding the column back the the original <code>DataFrame</code> is also a lot cheaper (since we don't require a join like in a normal window function).</p>
<p>However, for this operation to make sense, it is important that the columns used in <code>over([..])</code> are sorted!</p>
<h1 id="list-context"><a class="header" href="#list-context">List context</a></h1>
<p>An expression context we haven't discussed yet is the <code>List</code> context. This means simply we
can apply any expression on the elements of a <code>List</code>.</p>
<h1 id="row-wise-computations"><a class="header" href="#row-wise-computations">Row wise computations</a></h1>
<p>This context is ideal for computing things in row orientation.</p>
<p>Polars expressions work on columns that have the guarantee that they consist of homogeneous data.
Columns have this guarantee, rows in a <code>DataFrame</code> not so much.
Luckily we have a data type that has the guarantee that the rows are homogeneous: <code>pl.List</code> data type.</p>
<p>Let's say we have the following data:</p>
<pre><code class="language-python">grades = pl.DataFrame(
    {
        &quot;student&quot;: [&quot;bas&quot;, &quot;laura&quot;, &quot;tim&quot;, &quot;jenny&quot;],
        &quot;arithmetic&quot;: [10, 5, 6, 8],
        &quot;biology&quot;: [4, 6, 2, 7],
        &quot;geography&quot;: [8, 4, 9, 7],
    }
)
print(grades)
</code></pre>
<pre><code class="language-text">shape: (4, 4)
┌─────────┬────────────┬─────────┬───────────┐
│ student ┆ arithmetic ┆ biology ┆ geography │
│ ---     ┆ ---        ┆ ---     ┆ ---       │
│ str     ┆ i64        ┆ i64     ┆ i64       │
╞═════════╪════════════╪═════════╪═══════════╡
│ bas     ┆ 10         ┆ 4       ┆ 8         │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ laura   ┆ 5          ┆ 6       ┆ 4         │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ tim     ┆ 6          ┆ 2       ┆ 9         │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤
│ jenny   ┆ 8          ┆ 7       ┆ 7         │
└─────────┴────────────┴─────────┴───────────┘
</code></pre>
<p>If we want to compute the <code>rank</code> of all the columns except for <code>&quot;student&quot;</code>, we can collect those into a <code>list</code> data type:</p>
<p>This would give:</p>
<pre><code class="language-python">out = grades.select([pl.concat_list(pl.all().exclude(&quot;student&quot;)).alias(&quot;all_grades&quot;)])
print(out)
</code></pre>
<pre><code class="language-python">out = grades.select([
    pl.concat_list(pl.all().exclude(&quot;student&quot;)).alias(&quot;all_grades&quot;)
])
</code></pre>
<pre><code class="language-text">shape: (4, 1)
┌────────────┐
│ all_grades │
│ ---        │
│ list [i64] │
╞════════════╡
│ [10, 4, 8] │
├╌╌╌╌╌╌╌╌╌╌╌╌┤
│ [5, 6, 4]  │
├╌╌╌╌╌╌╌╌╌╌╌╌┤
│ [6, 2, 9]  │
├╌╌╌╌╌╌╌╌╌╌╌╌┤
│ [8, 7, 7]  │
└────────────┘
</code></pre>
<h2 id="running-polars-expression-on-list-elements"><a class="header" href="#running-polars-expression-on-list-elements">Running polars expression on list elements</a></h2>
<p>We can run <strong>any</strong> polars expression on the elements of a list with the <code>arr.eval</code> expression!
These expressions entirely run on polars' query engine and can run in parallel so will be super fast.</p>
<p>Let's expand the example from above with someting a little bit more interesting. Pandas allows you to compute the percentages
of the <code>rank</code> values. Polars doesn't provide such a keyword argument.
But because expressions are so versatile we can create our own percentage rank expression. Let's try that!</p>
<p>Note that we must <code>select</code> the list's element from the context. When we apply expressions over list elements. Any <code>col()/first()</code> selection suffices.</p>
<pre><code class="language-python"># the percentage rank expression
rank_pct = pl.col(&quot;&quot;).rank(reverse=True) / pl.col(&quot;&quot;).count()


grades.with_column(
    # create the list of homogeneous data
    pl.concat_list(pl.all().exclude(&quot;student&quot;)).alias(&quot;all_grades&quot;)
).select([
    # select all columns except the intermediate list
    pl.all().exclude(&quot;all_grades&quot;),
    # compute the rank by calling `arr.eval`
    pl.col(&quot;all_grades&quot;).arr.eval(rank_pct, parallel=True).alias(&quot;grades_rank&quot;)
])
</code></pre>
<p>This outputs:</p>
<pre><code>shape: (4, 5)
┌─────────┬────────────┬─────────┬───────────┬────────────────────────────────┐
│ student ┆ arithmetic ┆ biology ┆ geography ┆ grades_rank                    │
│ ---     ┆ ---        ┆ ---     ┆ ---       ┆ ---                            │
│ str     ┆ i64        ┆ i64     ┆ i64       ┆ list [f32]                     │
╞═════════╪════════════╪═════════╪═══════════╪════════════════════════════════╡
│ bas     ┆ 10         ┆ 4       ┆ 8         ┆ [0.333333, 1.0, 0.666667]      │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ laura   ┆ 5          ┆ 6       ┆ 4         ┆ [0.666667, 0.333333, 1.0]      │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ tim     ┆ 6          ┆ 2       ┆ 9         ┆ [0.666667, 1.0, 0.333333]      │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ jenny   ┆ 8          ┆ 7       ┆ 7         ┆ [0.333333, 0.833333, 0.833333] │
└─────────┴────────────┴─────────┴───────────┴────────────────────────────────┘

</code></pre>
<p>Note that this solution works for any expressions/operation you want to do row wise.</p>
<h1 id="numpy-interop"><a class="header" href="#numpy-interop">Numpy interop</a></h1>
<p><code>Polars</code> expressions support <code>NumPy</code> <a href="https://numpy.org/doc/stable/reference/ufuncs.html">ufuncs</a>. See <a href="https://numpy.org/doc/stable/reference/ufuncs.html#available-ufuncs">here</a>
for a list on all supported numpy functions.</p>
<p>This means that if a function is not provided by <code>Polars</code>, we can use <code>NumPy</code> and we still have fast columnar operation through
the <code>NumPy</code> API.</p>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<pre><code class="language-python">import polars as pl
import numpy as np

df = pl.DataFrame({&quot;a&quot;: [1, 2, 3], &quot;b&quot;: [4, 5, 6]})

out = df.select(
    [
        np.log(pl.all()).suffix(&quot;_log&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 2)
┌──────────┬──────────┐
│ a_log    ┆ b_log    │
│ ---      ┆ ---      │
│ f64      ┆ f64      │
╞══════════╪══════════╡
│ 0.0      ┆ 1.386294 │
├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤
│ 0.693147 ┆ 1.609438 │
├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤
│ 1.098612 ┆ 1.791759 │
└──────────┴──────────┘
</code></pre>
<h2 id="gotchas"><a class="header" href="#gotchas">Gotcha's</a></h2>
<p>Read more about the <a href="dsl//polars-book/user-guide/howcani/interop/numpy.html">gotcha's here</a>.</p>
<h1 id="custom-functions"><a class="header" href="#custom-functions">Custom functions</a></h1>
<p>You should be convinced by now that polar expressions are so powerful and flexible that the need for custom python functions
is much less needed than you might need in other libraries.</p>
<p>Still, you need to have the power to be able to pass an expression's state to a third party library or apply your black box function
over data in polars.</p>
<p>For this we provide the following expressions:</p>
<ul>
<li><code>map</code></li>
<li><code>apply</code></li>
</ul>
<h2 id="to-map-or-to-apply"><a class="header" href="#to-map-or-to-apply">To <code>map</code> or to <code>apply</code>.</a></h2>
<p>These functions have an important distinction in how they operate and consequently what data they will pass to the user.</p>
<p>A <code>map</code> passes the <code>Series</code> backed by the <code>expression</code> as is.</p>
<p><code>map</code> follows the same rules in both the <code>select</code> and the <code>groupby</code> context, this will
mean that the <code>Series</code> represents a column in a <code>DataFrame</code>. Note that in the <code>groupby</code> context, that column is not yet
aggregated!</p>
<p>Use cases for <code>map</code> are for instance passing the <code>Series</code> in an expression to a third party library. Below we show how
we could use <code>map</code> to pass an expression column to a neural network model.</p>
<pre><code class="language-python">df.with_column([
    pl.col(&quot;features&quot;).map(lambda s: MyNeuralNetwork.forward(s.to_numpy())).alias(&quot;activations&quot;)
])
</code></pre>
<p>Use cases for <code>map</code> in the <code>groupby</code> context are slim. They are only used for performance reasons, but can quite easily
lead to incorrect results. Let me explain why.</p>
<pre><code class="language-python">df = pl.DataFrame(
    {
        &quot;keys&quot;: [&quot;a&quot;, &quot;a&quot;, &quot;b&quot;],
        &quot;values&quot;: [10, 7, 1],
    }
)

out = df.groupby(&quot;keys&quot;, maintain_order=True).agg(
    [
        pl.col(&quot;values&quot;).map(lambda s: s.shift()).alias(&quot;shift_map&quot;),
        pl.col(&quot;values&quot;).shift().alias(&quot;shift_expression&quot;),
    ]
)
print(df)
</code></pre>
<pre><code>shape: (3, 2)
┌──────┬────────┐
│ keys ┆ values │
│ ---  ┆ ---    │
│ str  ┆ i64    │
╞══════╪════════╡
│ a    ┆ 10     │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ a    ┆ 7      │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ b    ┆ 1      │
└──────┴────────┘

</code></pre>
<p>In the snippet above we groupby the <code>&quot;keys&quot;</code> column. That means we have the following groups:</p>
<pre><code class="language-c">&quot;a&quot; -&gt; [10, 7]
&quot;b&quot; -&gt; [1]
</code></pre>
<p>If we would then apply a <code>shift</code> operation to the right, we'd expect:</p>
<pre><code class="language-c">&quot;a&quot; -&gt; [null, 10]
&quot;b&quot; -&gt; [null]
</code></pre>
<p>Now, let's print and see what we've got.</p>
<pre><code class="language-python">print(out)
</code></pre>
<pre><code class="language-text">shape: (2, 3)
┌──────┬────────────┬──────────────────┐
│ keys ┆ shift_map  ┆ shift_expression │
│ ---  ┆ ---        ┆ ---              │
│ str  ┆ list [i64] ┆ list [i64]       │
╞══════╪════════════╪══════════════════╡
│ a    ┆ [null, 10] ┆ [null, 10]       │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ b    ┆ [7]        ┆ [null]           │
└──────┴────────────┴──────────────────┘
</code></pre>
<p>Ouch.. we clearly get the wrong results here. Group <code>&quot;b&quot;</code> even got a value from group <code>&quot;a&quot;</code> 😵.</p>
<p>This went horribly wrong, because the <code>map</code> applies the function before we aggregate! So that means the whole column
<code>[10, 7, 1</code>] got shifted to <code>[null, 10, 7]</code> and was then aggregated.</p>
<p>So my advice is to never use <code>map</code> in the <code>groupby</code> context unless you know you need it and know what you are doing.</p>
<h2 id="to-apply"><a class="header" href="#to-apply">To <code>apply</code></a></h2>
<p>Luckily we can fix previous example with <code>apply</code>. <code>apply</code> works on the smallest logical elements for that operation.</p>
<p>That is:</p>
<ul>
<li><code>select context</code> -&gt; single elements</li>
<li><code>groupby context</code> -&gt; single groups</li>
</ul>
<p>So with <code>apply</code> we should be able to fix our example:</p>
<pre><code class="language-python">out = df.groupby(&quot;keys&quot;, maintain_order=True).agg(
    [
        pl.col(&quot;values&quot;).apply(lambda s: s.shift()).alias(&quot;shift_map&quot;),
        pl.col(&quot;values&quot;).shift().alias(&quot;shift_expression&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (2, 3)
┌──────┬────────────┬──────────────────┐
│ keys ┆ shift_map  ┆ shift_expression │
│ ---  ┆ ---        ┆ ---              │
│ str  ┆ list [i64] ┆ list [i64]       │
╞══════╪════════════╪══════════════════╡
│ a    ┆ [null, 10] ┆ [null, 10]       │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ b    ┆ [null]     ┆ [null]           │
└──────┴────────────┴──────────────────┘
</code></pre>
<p>And observe, a valid result! 🎉</p>
<h2 id="apply-in-the-select-context"><a class="header" href="#apply-in-the-select-context"><code>apply</code> in the <code>select</code> context</a></h2>
<p>In the <code>select</code> context, the <code>apply</code> expression passes elements of the column to the python function.</p>
<p><em>Note that you are
now running python, this will be slow.</em></p>
<p>Let's go through some examples to see what to expect. We will continue with the <code>DataFrame</code> we defined at the start of
this section and show an example with the <code>apply</code> function and a counter example where we use the expression API to
achieve the same goals.</p>
<h3 id="adding-a-counter"><a class="header" href="#adding-a-counter">Adding a counter</a></h3>
<p>In this example we create a global <code>counter</code> and then add the integer <code>1</code> to the global state at every element processed.
Every iteration the result of the increment will be added to the element value.</p>
<pre><code class="language-python">counter = 0


def add_counter(val: int) -&gt; int:
    global counter
    counter += 1
    return counter + val


out = df.select(
    [
        pl.col(&quot;values&quot;).apply(add_counter).alias(&quot;solution_apply&quot;),
        (pl.col(&quot;values&quot;) + pl.arange(1, pl.count() + 1)).alias(&quot;solution_expr&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 2)
┌────────────────┬───────────────┐
│ solution_apply ┆ solution_expr │
│ ---            ┆ ---           │
│ i64            ┆ i64           │
╞════════════════╪═══════════════╡
│ 11             ┆ 11            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 9              ┆ 9             │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 4              ┆ 4             │
└────────────────┴───────────────┘
</code></pre>
<h3 id="combining-multiple-column-values"><a class="header" href="#combining-multiple-column-values">Combining multiple column values</a></h3>
<p>If we want to have access to values of different columns in a single <code>apply</code> function call, we can create <code>struct</code> data
type. This data type collects those columns as fields in the <code>struct</code>. So if we'd create a struct from the columns
<code>&quot;keys&quot;</code> and <code>&quot;values&quot;</code>, we would get the following struct elements:</p>
<pre><code class="language-python">[
    {&quot;keys&quot;: &quot;a&quot;, &quot;values&quot;: 10},
    {&quot;keys&quot;: &quot;a&quot;, &quot;values&quot;: 7},
    {&quot;keys&quot;: &quot;b&quot;, &quot;values&quot;: 1},
]
</code></pre>
<p>Those would be passed as <code>dict</code> to the calling python function and can thus be indexed by <code>field: str</code>.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.struct([&quot;keys&quot;, &quot;values&quot;]).apply(lambda x: len(x[&quot;keys&quot;]) + x[&quot;values&quot;]).alias(&quot;solution_apply&quot;),
        (pl.col(&quot;keys&quot;).str.lengths() + pl.col(&quot;values&quot;)).alias(&quot;solution_expr&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 2)
┌────────────────┬───────────────┐
│ solution_apply ┆ solution_expr │
│ ---            ┆ ---           │
│ i64            ┆ i64           │
╞════════════════╪═══════════════╡
│ 11             ┆ 11            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 8              ┆ 8             │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2              ┆ 2             │
└────────────────┴───────────────┘
</code></pre>
<h3 id="return-types"><a class="header" href="#return-types">Return types?</a></h3>
<p>Custom python functions are black boxes for polars. We really don't know what kind of black arts you are doing, so we have
to infer and try our best to understand what you meant.</p>
<p>As a user it helps to understand what we do to better utilize custom functions.</p>
<p>The data type is automatically inferred. We do that by waiting for the first non-null value. That value will then be used
to determine the type of the <code>Series</code>.</p>
<p>The mapping of python types to polars data types is as follows:</p>
<ul>
<li><code>int</code> -&gt; <code>Int64</code></li>
<li><code>float</code> -&gt; <code>Float64</code></li>
<li><code>bool</code> -&gt; <code>Boolean</code></li>
<li><code>str</code> -&gt; <code>Utf8</code></li>
<li><code>list[tp]</code> -&gt; <code>List[tp]</code> (where the inner type is inferred with the same rules)</li>
<li><code>dict[str, [tp]]</code> -&gt; <code>struct</code></li>
<li><code>Any</code> -&gt; <code>object</code> (Prevent this at all times)</li>
</ul>
<pre><code class="language-python">import polars as pl

</code></pre>
<h1 id="expressions"><a class="header" href="#expressions">Expressions</a></h1>
<p><code>fn(Series) -&gt; Series</code></p>
<ul>
<li>Lazily evaluated
<ul>
<li>Can be optimized</li>
<li>Gives the library writer context and informed decision can be made</li>
</ul>
</li>
<li>Embarrassingly parallel</li>
<li>Context dependent
<ul>
<li>selection / projection -&gt; <code>Series</code> = <strong>COLUMN, LITERAL or VALUE</strong></li>
<li>aggregation -&gt; <code>Series</code> = <strong>GROUPS</strong></li>
</ul>
</li>
</ul>
<pre><code class="language-python">df = pl.DataFrame(
    {
        &quot;A&quot;: [1, 2, 3, 4, 5],
        &quot;fruits&quot;: [&quot;banana&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;apple&quot;, &quot;banana&quot;],
        &quot;B&quot;: [5, 4, 3, 2, 1],
        &quot;cars&quot;: [&quot;beetle&quot;, &quot;audi&quot;, &quot;beetle&quot;, &quot;beetle&quot;, &quot;beetle&quot;],
        &quot;optional&quot;: [28, 300, None, 2, -30],
    }
)
df
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
fruits
</th>
<th>
B
</th>
<th>
cars
</th>
<th>
optional
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
</tr>
<tr>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
</tr>
<tr>
<td>
3
</td>
<td>
"apple"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
<td>
null
</td>
</tr>
<tr>
<td>
4
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
<td>
2
</td>
</tr>
<tr>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
</tr>
</tbody>
</table>
</div>
<h1 id="selection-context-1"><a class="header" href="#selection-context-1">Selection context</a></h1>
<pre><code class="language-python"># We can select by name

(df.select([
    pl.col(&quot;A&quot;),
    &quot;B&quot;,      # the col part is inferred
    pl.lit(&quot;B&quot;),  # we must tell polars we mean the literal &quot;B&quot;
    pl.col(&quot;fruits&quot;),
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
B
</th>
<th>
literal
</th>
<th>
fruits
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
str
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
5
</td>
<td>
"B"
</td>
<td>
"banana"
</td>
</tr>
<tr>
<td>
2
</td>
<td>
4
</td>
<td>
"B"
</td>
<td>
"banana"
</td>
</tr>
<tr>
<td>
3
</td>
<td>
3
</td>
<td>
"B"
</td>
<td>
"apple"
</td>
</tr>
<tr>
<td>
4
</td>
<td>
2
</td>
<td>
"B"
</td>
<td>
"apple"
</td>
</tr>
<tr>
<td>
5
</td>
<td>
1
</td>
<td>
"B"
</td>
<td>
"banana"
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># you can select columns with a regex if it starts with '^' and ends with '$'

(df.select([
    pl.col(&quot;^A|B$&quot;).sum()
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
B
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
15
</td>
<td>
15
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># you can select multiple columns by name

(df.select([
    pl.col([&quot;A&quot;, &quot;B&quot;]).sum()
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
B
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
15
</td>
<td>
15
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We select everything in normal order
# Then we select everything in reversed order

(df.select([
    pl.all(),
    pl.all().reverse().suffix(&quot;_reverse&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
fruits
</th>
<th>
B
</th>
<th>
cars
</th>
<th>
optional
</th>
<th>
A_reverse
</th>
<th>
fruits_reverse
</th>
<th>
B_reverse
</th>
<th>
cars_reverse
</th>
<th>
optional_reverse
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
</tr>
<tr>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
<td>
4
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
<td>
2
</td>
</tr>
<tr>
<td>
3
</td>
<td>
"apple"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
<td>
null
</td>
<td>
3
</td>
<td>
"apple"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
<td>
null
</td>
</tr>
<tr>
<td>
4
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
<td>
2
</td>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
</tr>
<tr>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># all expressions run in parallel
# single valued `Series` are broadcasted to the shape of the `DataFrame`

(df.select([
    pl.all(),
    pl.all().sum().suffix(&quot;_sum&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
fruits
</th>
<th>
B
</th>
<th>
cars
</th>
<th>
optional
</th>
<th>
A_sum
</th>
<th>
fruits_sum
</th>
<th>
B_sum
</th>
<th>
cars_sum
</th>
<th>
optional_sum
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
<tr>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
<tr>
<td>
3
</td>
<td>
"apple"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
<tr>
<td>
4
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
<td>
2
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
<tr>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># there are `str` and `dt` namespaces for specialized functions

predicate = pl.col(&quot;fruits&quot;).str.contains(&quot;^b.*&quot;)

(df.select([
    predicate
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
</tr>
<tr>
<td>
bool
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
true
</td>
</tr>
<tr>
<td>
true
</td>
</tr>
<tr>
<td>
false
</td>
</tr>
<tr>
<td>
false
</td>
</tr>
<tr>
<td>
true
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># use the predicate to filter

df.filter(predicate)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
fruits
</th>
<th>
B
</th>
<th>
cars
</th>
<th>
optional
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
</tr>
<tr>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
</tr>
<tr>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># predicate expressions can be used to filter

(df.select([
    pl.col(&quot;A&quot;).filter(pl.col(&quot;fruits&quot;).str.contains(&quot;^b.*&quot;)).sum(),
    (pl.col(&quot;B&quot;).filter(pl.col(&quot;cars&quot;).str.contains(&quot;^b.*&quot;)).sum() * pl.col(&quot;B&quot;).sum()).alias(&quot;some_compute()&quot;),
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
some_compute()
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
8
</td>
<td>
165
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can do arithmetic on columns and (literal) values
# can be evaluated to 1 without programmer knowing

some_var = 1

(df.select([
    ((pl.col(&quot;A&quot;) / 124.0 * pl.col(&quot;B&quot;)) / pl.sum(&quot;B&quot;) * some_var).alias(&quot;computed&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
computed
</th>
</tr>
<tr>
<td>
f64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
0.0
</td>
</tr>
<tr>
<td>
0.0
</td>
</tr>
<tr>
<td>
0.0
</td>
</tr>
<tr>
<td>
0.0
</td>
</tr>
<tr>
<td>
0.0
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can combine columns by a predicate

(df.select([
    &quot;fruits&quot;,
    &quot;B&quot;,
    pl.when(pl.col(&quot;fruits&quot;) == &quot;banana&quot;).then(pl.col(&quot;B&quot;)).otherwise(-1).alias(&quot;b&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B
</th>
<th>
b
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"banana"
</td>
<td>
5
</td>
<td>
5
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
4
</td>
<td>
4
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
3
</td>
<td>
-1
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
2
</td>
<td>
-1
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can combine columns by a fold operation on column level

(df.select([
    &quot;A&quot;,
    &quot;B&quot;,
    pl.fold(0, lambda a, b: a + b, [pl.col(&quot;A&quot;), &quot;B&quot;, pl.col(&quot;B&quot;)**2, pl.col(&quot;A&quot;) / 2.0]).alias(&quot;fold&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
B
</th>
<th>
fold
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
<td>
f64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
5
</td>
<td>
31
</td>
</tr>
<tr>
<td>
2
</td>
<td>
4
</td>
<td>
23
</td>
</tr>
<tr>
<td>
3
</td>
<td>
3
</td>
<td>
16
</td>
</tr>
<tr>
<td>
4
</td>
<td>
2
</td>
<td>
12
</td>
</tr>
<tr>
<td>
5
</td>
<td>
1
</td>
<td>
9
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># even combine all

(df.select([
    pl.arange(0, df.height).alias(&quot;idx&quot;),
    &quot;A&quot;,
    pl.col(&quot;A&quot;).shift().alias(&quot;A_shifted&quot;),
    pl.concat_str(pl.all(), &quot;-&quot;).alias(&quot;str_concat_1&quot;),  # prefer this
    pl.fold(pl.col(&quot;A&quot;), lambda a, b: a + &quot;-&quot; + b, pl.all().exclude(&quot;A&quot;)).alias(&quot;str_concat_2&quot;),  # over this (accidentally O(n^2))
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
idx
</th>
<th>
A
</th>
<th>
A_shifted
</th>
<th>
str_concat_1
</th>
<th>
str_concat_2
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
str
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
0
</td>
<td>
1
</td>
<td>
null
</td>
<td>
"1-banana-5-beetle-28"
</td>
<td>
"1-banana-5-beetle-28"
</td>
</tr>
<tr>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
"2-banana-4-audi-300"
</td>
<td>
"2-banana-4-audi-300"
</td>
</tr>
<tr>
<td>
2
</td>
<td>
3
</td>
<td>
2
</td>
<td>
null
</td>
<td>
null
</td>
</tr>
<tr>
<td>
3
</td>
<td>
4
</td>
<td>
3
</td>
<td>
"4-apple-2-beetle-2"
</td>
<td>
"4-apple-2-beetle-2"
</td>
</tr>
<tr>
<td>
4
</td>
<td>
5
</td>
<td>
4
</td>
<td>
"5-banana-1-beetle--30"
</td>
<td>
"5-banana-1-beetle--30"
</td>
</tr>
</tbody>
</table>
</div>
<h1 id="aggregation-context"><a class="header" href="#aggregation-context">Aggregation context</a></h1>
<ul>
<li>expressions are applied over groups instead of columns</li>
</ul>
<pre><code class="language-python"># we can still combine many expressions

(df.sort(&quot;cars&quot;).groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).sum().alias(&quot;B_sum&quot;),
        pl.sum(&quot;B&quot;).alias(&quot;B_sum2&quot;),  # syntactic sugar for the first
        pl.first(&quot;fruits&quot;).alias(&quot;fruits_first&quot;),
        pl.count(&quot;A&quot;).alias(&quot;count&quot;),
        pl.col(&quot;cars&quot;).reverse()
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_sum
</th>
<th>
B_sum2
</th>
<th>
fruits_first
</th>
<th>
count
</th>
<th>
cars
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
u32
</td>
<td>
list
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
[beetle, beetle, audi]
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
[beetle, beetle]
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can explode the list column &quot;cars&quot;

(df.sort(&quot;cars&quot;).groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).sum().alias(&quot;B_sum&quot;),
        pl.sum(&quot;B&quot;).alias(&quot;B_sum2&quot;),  # syntactic sugar for the first
        pl.first(&quot;fruits&quot;).alias(&quot;fruits_first&quot;),
        pl.count(&quot;A&quot;).alias(&quot;count&quot;),
        pl.col(&quot;cars&quot;).reverse()
    ])).explode(&quot;cars&quot;)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_sum
</th>
<th>
B_sum2
</th>
<th>
fruits_first
</th>
<th>
count
</th>
<th>
cars
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
u32
</td>
<td>
str
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"audi"
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python">(df.groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).sum().alias(&quot;B_sum&quot;),
        pl.sum(&quot;B&quot;).alias(&quot;B_sum2&quot;),  # syntactic sugar for the first
        pl.first(&quot;fruits&quot;).alias(&quot;fruits_first&quot;),
        pl.count(),
        pl.col(&quot;B&quot;).shift().alias(&quot;B_shifted&quot;)
    ])
 .explode(&quot;B_shifted&quot;)
)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_sum
</th>
<th>
B_sum2
</th>
<th>
fruits_first
</th>
<th>
count
</th>
<th>
B_shifted
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
u32
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
null
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
null
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
5
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can explode the list column &quot;cars&quot;

(df.sort(&quot;cars&quot;).groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).sum(),
        pl.sum(&quot;B&quot;).alias(&quot;B_sum2&quot;),  # syntactic sugar for the first
        pl.first(&quot;fruits&quot;).alias(&quot;fruits_first&quot;),
        pl.count(&quot;A&quot;).alias(&quot;count&quot;),
        pl.col(&quot;cars&quot;).reverse()
    ])).explode(&quot;cars&quot;)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_sum
</th>
<th>
B_sum2
</th>
<th>
fruits_first
</th>
<th>
count
</th>
<th>
cars
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
u32
</td>
<td>
str
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"audi"
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># we can also get the list of the groups

(df.groupby(&quot;fruits&quot;)
    .agg([
         pl.col(&quot;B&quot;).shift().alias(&quot;shift_B&quot;),
         pl.col(&quot;B&quot;).reverse().alias(&quot;rev_B&quot;),
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
shift_B
</th>
<th>
rev_B
</th>
</tr>
<tr>
<td>
str
</td>
<td>
list
</td>
<td>
list
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
[null, 3]
</td>
<td>
[2, 3]
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
[null, 5, 4]
</td>
<td>
[1, 4, 5]
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># we can do predicates in the groupby as well

(df.groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).filter(pl.col(&quot;B&quot;) &gt; 1).list().keep_name(),
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B
</th>
</tr>
<tr>
<td>
str
</td>
<td>
list
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"banana"
</td>
<td>
[5, 4]
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
[3, 2]
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># and sum only by the values where the predicates are true

(df.groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).filter(pl.col(&quot;B&quot;) &gt; 1).mean(),
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_mean
</th>
</tr>
<tr>
<td>
str
</td>
<td>
f64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"banana"
</td>
<td>
4.5
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
2.5
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># Another example

(df.groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).shift_and_fill(1, fill_value=0).alias(&quot;shifted&quot;),
        pl.col(&quot;B&quot;).shift_and_fill(1, fill_value=0).sum().alias(&quot;shifted_sum&quot;),
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
shifted
</th>
<th>
shifted_sum
</th>
</tr>
<tr>
<td>
str
</td>
<td>
list
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
[0, 3]
</td>
<td>
3
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
[0, 5, 4]
</td>
<td>
9
</td>
</tr>
</tbody>
</table>
</div>
<h1 id="window-functions"><a class="header" href="#window-functions">Window functions!</a></h1>
<ul>
<li>Expression with superpowers.</li>
<li>Aggregation in selection context</li>
</ul>
<pre><code class="language-python">pl.col(&quot;foo&quot;).aggregation_expression(..).over(&quot;column_used_to_group&quot;)
</code></pre>
<pre><code class="language-python"># groupby 2 different columns

(df.select([
    &quot;fruits&quot;,
    &quot;cars&quot;,
    &quot;B&quot;,
    pl.col(&quot;B&quot;).sum().over(&quot;fruits&quot;).alias(&quot;B_sum_by_fruits&quot;),
    pl.col(&quot;B&quot;).sum().over(&quot;cars&quot;).alias(&quot;B_sum_by_cars&quot;),
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
cars
</th>
<th>
B
</th>
<th>
B_sum_by_fruits
</th>
<th>
B_sum_by_cars
</th>
</tr>
<tr>
<td>
str
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
"beetle"
</td>
<td>
3
</td>
<td>
5
</td>
<td>
11
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
"beetle"
</td>
<td>
2
</td>
<td>
5
</td>
<td>
11
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
"beetle"
</td>
<td>
5
</td>
<td>
10
</td>
<td>
11
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
"audi"
</td>
<td>
4
</td>
<td>
10
</td>
<td>
4
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
"beetle"
</td>
<td>
1
</td>
<td>
10
</td>
<td>
11
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># reverse B by groups and show the results in original DF

(df.select([
    &quot;fruits&quot;,
    &quot;B&quot;,
    pl.col(&quot;B&quot;).reverse().over(&quot;fruits&quot;).alias(&quot;B_reversed_by_fruits&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B
</th>
<th>
B_reversed_by_fruits
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
3
</td>
<td>
2
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
5
</td>
<td>
1
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
4
</td>
<td>
4
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
1
</td>
<td>
5
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># Lag a column within &quot;fruits&quot;

(df.select([
    &quot;fruits&quot;,
    &quot;B&quot;,
    pl.col(&quot;B&quot;).shift().over(&quot;fruits&quot;).alias(&quot;lag_B_by_fruits&quot;)
]))

</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B
</th>
<th>
lag_B_by_fruits
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
3
</td>
<td>
null
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
5
</td>
<td>
null
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
4
</td>
<td>
5
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
1
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
</div>
<h1 id="expression-api"><a class="header" href="#expression-api">Expression API</a></h1>
<p>The full list of possible expressions is available on the <a href="https://pola-rs.github.io/polars/py-polars/html/reference/expression.html"><code>Expr</code></a>
class definition in the reference guide.</p>
<h1 id="video-introduction"><a class="header" href="#video-introduction">Video Introduction</a></h1>
<p>Don't enjoy reading? Take a look at this introduction video on <code>Polars</code> and its expressions.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/iwGIuGk5nCE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<h1 id="indexing"><a class="header" href="#indexing">Indexing</a></h1>
<p>The <code>Polars</code> <code>DataFrame</code> doesn't have an index, therefore indexing behavior can be consistent without the need of a <code>df.loc</code>,
<code>df.iloc</code>, or a <code>df.at</code> operation.</p>
<p>The rules are as follows (depending on the datatypes of the values):</p>
<ul>
<li>
<p><strong>numeric</strong></p>
<ul>
<li>axis 0: row</li>
<li>axis 1: column</li>
</ul>
</li>
<li>
<p><strong>numeric + strings</strong></p>
<ul>
<li>axis 0: row (only accept numbers here)</li>
<li>axis 1: column (accept numeric + string values)</li>
</ul>
</li>
<li>
<p><strong>only strings</strong></p>
<ul>
<li>axis 0: column</li>
<li>axis 1: error</li>
</ul>
</li>
<li>
<p><strong>expressions</strong></p>
<p><em>All expression evaluations are executed in parallel</em></p>
<ul>
<li>axis 0: column</li>
<li>axis 1: column</li>
<li>..</li>
<li>axis n: column</li>
</ul>
</li>
</ul>
<h2 id="comparison-with-pandas"><a class="header" href="#comparison-with-pandas">Comparison with pandas</a></h2>
<table><thead><tr><th>pandas</th><th>polars</th></tr></thead><tbody>
<tr><td>select row<br> <code>df.iloc[2]</code></td><td><code>df[2, :]</code></td></tr>
<tr><td>select several rows by their indices<br> <code>df.iloc[[2, 5, 6]]</code></td><td><code>df[[2, 5, 6], :]</code></td></tr>
<tr><td>select slice of rows<br> <code>df.iloc[2:6]</code></td><td><code>df[2:6, :]</code></td></tr>
<tr><td>select rows using a boolean mask<br> <code>df.iloc[True, True, False]</code></td><td><code>df[[True, True, False]]</code></td></tr>
<tr><td>select rows by a predicate condition<br> <code>df.loc[df[&quot;A&quot;] &gt; 3]</code></td><td><code>df[df[&quot;A&quot;] &gt; 3]</code></td></tr>
<tr><td>select slice of columns<br> <code>df.iloc[:, 1:3]</code></td><td><code>df[:, 1:3]</code></td></tr>
<tr><td>select slice of columns by string order<br> <code>df.loc[:, &quot;A&quot;:&quot;Z&quot;]</code></td><td><code>df[:, &quot;A&quot;:&quot;Z&quot;]</code></td></tr>
<tr><td>select a single value (scalar)<br> <code>df.loc[2, &quot;A&quot;]</code></td><td><code>df[2, &quot;A&quot;]</code></td></tr>
<tr><td>select a single value (scalar)<br> <code>df.iloc[2, 1]</code></td><td><code>df[2, 1]</code></td></tr>
<tr><td>select a single value (Series/DataFrame)<br> <code>df.loc[2, [&quot;A&quot;]]</code></td><td><code>df[2, [&quot;A&quot;]]</code></td></tr>
<tr><td>select a single value (Series/DataFrame)<br> <code>df.iloc[2, [1]]</code></td><td><code>df[2, [1]]</code></td></tr>
</tbody></table>
<h2 id="anti-pattern"><a class="header" href="#anti-pattern">Anti-pattern</a></h2>
<p>Indexing polars by boolean masks is considered an anti-pattern and the functionality may be removed in the future.
Polars strongly favours the expression API in combination with <code>select</code> and <code>filter</code> in favor of accessing by index.</p>
<h1 id="data-types"><a class="header" href="#data-types">Data types</a></h1>
<p><code>Polars</code> is entirely based on <code>Arrow</code> data types and backed by <code>Arrow</code> memory arrays. This makes data processing
cache-efficient and well-supported for Inter Process Communication. Most data types follow the exact implementation
from <code>Arrow</code>, with exception of <code>Utf8</code> (this is actually <code>LargeUtf8</code>), <code>Categorical</code>, and <code>Object</code> (support is limited).</p>
<p>The data types are:</p>
<ul>
<li><code>Int8</code>: 8-bit signed integer.</li>
<li><code>Int16</code>: 16-bit signed integer.</li>
<li><code>Int32</code>: 32-bit signed integer.</li>
<li><code>Int64</code>: 64-bit signed integer.</li>
<li><code>UInt8</code>: 8-bit unsigned integer.</li>
<li><code>UInt16</code>: 16-bit unsigned integer.</li>
<li><code>UInt32</code>: 32-bit unsigned integer.</li>
<li><code>UInt64</code>: 64-bit unsigned integer.</li>
<li><code>Float32</code>: 32-bit floating point.</li>
<li><code>Float64</code>: 64-bit floating point.</li>
<li><code>Boolean</code>: Boolean type effectively bit packed.</li>
<li><code>Utf8</code>: String data (this is actually <code>Arrow</code> <code>LargeUtf8</code> internally).</li>
<li><code>List</code>: A list array contains a child array containing the list values and an offset array. (this is actually <code>Arrow</code> <code>LargeList</code> internally).</li>
<li><code>Struct</code>: A struct array is represented as <code>Vec&lt;Series&gt;</code> and is useful to pack multiple/heterogenous values in a single column.</li>
<li><code>Date</code>: Date representation, internally represented as days since UNIX epoch encoded by a 32-bit signed integer.</li>
<li><code>Datetime</code>: Datetime representation, internally represented as nanoseconds since UNIX epoch encoded by a 64-bit signed integer.</li>
<li><code>Duration</code>: A timedelate type. Created when subtracting <code>Date/Datetime</code>.</li>
<li><code>Time</code>: Time representation, internally represented as nanoseconds since midnight.</li>
<li><code>Object</code>: A limited supported data type that can be any value.</li>
</ul>
<p>To learn more about the internal representation of these data types, check the <a href="https://arrow.apache.org/docs/format/Columnar.html"><code>Arrow</code> columnar format</a>.</p>
<h1 id="coming-from-pandas"><a class="header" href="#coming-from-pandas">Coming from pandas</a></h1>
<p>Users coming from <code>Pandas</code> generally need to know one thing...</p>
<pre><code>polars != pandas
</code></pre>
<p>If your <code>Polars</code> code looks like it could be <code>Pandas</code> code, it might run, but it likely runs slower than it should.</p>
<p>Let's go through some typical <code>Pandas</code> code and see how we might write that in <code>Polars</code>.</p>
<h2 id="column-assignment"><a class="header" href="#column-assignment">Column assignment</a></h2>
<h3 id="pandas"><a class="header" href="#pandas"><code>Pandas</code></a></h3>
<pre><code class="language-python"># executes sequential
df[&quot;a&quot;] = df[&quot;b&quot;] * 10
df[&quot;c&quot;] = df[&quot;b&quot;] * 100
</code></pre>
<h3 id="polars"><a class="header" href="#polars"><code>Polars</code></a></h3>
<pre><code class="language-python"># executes in parallel
df.with_columns([
    (pl.col(&quot;b&quot;) * 10).alias(&quot;a&quot;),
    (pl.col(&quot;b&quot;) * 100).alias(&quot;c&quot;),
])
</code></pre>
<h2 id="column-asignment-based-on-predicate"><a class="header" href="#column-asignment-based-on-predicate">Column asignment based on predicate</a></h2>
<h3 id="pandas-1"><a class="header" href="#pandas-1"><code>Pandas</code></a></h3>
<pre><code class="language-python">df.loc[df[&quot;c&quot;] == 2, &quot;a&quot;] = df.loc[df[&quot;c&quot;] == 2, &quot;b&quot;]
</code></pre>
<h3 id="polars-1"><a class="header" href="#polars-1"><code>Polars</code></a></h3>
<pre><code class="language-python">df.with_column(
    pl.when(pl.col(&quot;c&quot;) == 2)
    .then(pl.col(&quot;b&quot;))
    .otherwise(pl.col(&quot;a&quot;)).alias(&quot;a&quot;)
)
</code></pre>
<p>Note that <code>Polars</code> way is pure, thus the original <code>DataFrame</code> is not modified. The <code>mask</code> is also not computed twice as in <code>Pandas</code>.
You could prevent this in <code>Pandas</code>, but that would require setting a temporary variable.
Additionally polars can compute every branch of an <code>if -&gt; then -&gt; otherwise</code> in parallel. This is valuable, when the branches
get more expensive to compute.</p>
<h2 id="filtering-1"><a class="header" href="#filtering-1">Filtering</a></h2>
<h3 id="pandas-2"><a class="header" href="#pandas-2"><code>Pandas</code></a></h3>
<pre><code class="language-python">df.loc[(df['sqft_living'] &gt; 2500) &amp; (df['price'] &lt; 300000)]
</code></pre>
<h3 id="polars-2"><a class="header" href="#polars-2"><code>Polars</code></a></h3>
<pre><code class="language-python">df.filter(
    (pl.col(&quot;m2_living&quot;) &gt; 2500) &amp; (pl.col(&quot;price&quot;) &lt; 300000)
)
</code></pre>
<blockquote>
<p>This content is under construction. Missing something? Submit a PR! 🙂</p>
</blockquote>
<h2 id="no-indexes"><a class="header" href="#no-indexes">No Indexes</a></h2>
<p>They are not needed! Not having them makes things easier. Convince us otherwise!</p>
<h2 id="pandas-transform"><a class="header" href="#pandas-transform">Pandas transform</a></h2>
<p>The <code>Pandas</code> documentation demonstrates an operation on a groupby called <code>transform</code>.</p>
<h3 id="pandas-3"><a class="header" href="#pandas-3"><code>Pandas</code></a></h3>
<pre><code class="language-python">df = pd.DataFrame({
    &quot;c&quot;: [1, 1, 1, 2, 2, 2, 2],
    &quot;type&quot;: [&quot;m&quot;, &quot;n&quot;, &quot;o&quot;, &quot;m&quot;, &quot;m&quot;, &quot;n&quot;, &quot;n&quot;]
})

df[&quot;size&quot;] = df.groupby(&quot;c&quot;)[&quot;type&quot;].transform(len)
</code></pre>
<p>Here <code>Pandas</code> does a groupby on <code>&quot;c&quot;</code>, takes column <code>&quot;type&quot;</code>, computes the group <code>len</code>, and then joins the result back to the original <code>DataFrame</code>
producing:</p>
<pre><code>   c type size
0  1    m    3
1  1    n    3
2  1    o    3
3  2    m    4
4  2    m    4
5  2    n    4
6  2    n    4
</code></pre>
<h3 id="polars-3"><a class="header" href="#polars-3"><code>Polars</code></a></h3>
<p>In <code>Polars</code> the same can be achieved with <code>window</code> functions.</p>
<pre><code class="language-python">df.select([
    pl.all(),
    pl.col(&quot;type&quot;).count().over(&quot;c&quot;).alias(&quot;size&quot;)
])
</code></pre>
<pre><code>shape: (7, 3)
┌─────┬──────┬──────┐
│ c   ┆ type ┆ size │
│ --- ┆ ---  ┆ ---  │
│ i64 ┆ str  ┆ u32  │
╞═════╪══════╪══════╡
│ 1   ┆ m    ┆ 3    │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 1   ┆ n    ┆ 3    │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 1   ┆ o    ┆ 3    │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 2   ┆ m    ┆ 4    │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 2   ┆ m    ┆ 4    │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 2   ┆ n    ┆ 4    │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 2   ┆ n    ┆ 4    │
└─────┴──────┴──────┘
</code></pre>
<p>Because we can store the whole operation in a single expression, we can combine several <code>window</code> functions and
even combine different groups!</p>
<p><code>Polars</code> will cache window expressions that are applied over the same group, so storing them in a single <code>select</code> is both
convenient <strong>and</strong> optimal.</p>
<pre><code class="language-python">df.select([
    pl.all(),
    pl.col(&quot;c&quot;).count().over(&quot;c&quot;).alias(&quot;size&quot;),
    pl.col(&quot;c&quot;).sum().over(&quot;type&quot;).alias(&quot;sum&quot;),
    pl.col(&quot;c&quot;).reverse().over(&quot;c&quot;).flatten().alias(&quot;reverse_type&quot;)
])
</code></pre>
<pre><code>shape: (7, 5)
┌─────┬──────┬──────┬─────┬──────────────┐
│ c   ┆ type ┆ size ┆ sum ┆ reverse_type │
│ --- ┆ ---  ┆ ---  ┆ --- ┆ ---          │
│ i64 ┆ str  ┆ u32  ┆ i64 ┆ i64          │
╞═════╪══════╪══════╪═════╪══════════════╡
│ 1   ┆ m    ┆ 3    ┆ 5   ┆ 2            │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 1   ┆ n    ┆ 3    ┆ 5   ┆ 2            │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 1   ┆ o    ┆ 3    ┆ 1   ┆ 2            │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2   ┆ m    ┆ 4    ┆ 5   ┆ 2            │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2   ┆ m    ┆ 4    ┆ 5   ┆ 1            │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2   ┆ n    ┆ 4    ┆ 5   ┆ 1            │
├╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2   ┆ n    ┆ 4    ┆ 5   ┆ 1            │
└─────┴──────┴──────┴─────┴──────────────┘

</code></pre>
<h1 id="coming-from-apache-spark"><a class="header" href="#coming-from-apache-spark">Coming from Apache Spark</a></h1>
<h2 id="column-based-api-vs-row-based-api"><a class="header" href="#column-based-api-vs-row-based-api">Column-based API vs. Row-based API</a></h2>
<p>Whereas the <code>Spark</code> <code>DataFrame</code> is analogous to a collection of rows, a <code>Polars</code> <code>DataFrame</code> is closer to a collection of columns. This means that you can combine columns in <code>Polars</code> in ways that are not possible in <code>Spark</code>, because <code>Spark</code> preserves the relationship of the data in each row.</p>
<p>Consider this sample dataset:</p>
<pre><code class="language-python">import polars as pl

df = pl.DataFrame({
    &quot;foo&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;d&quot;],
    &quot;bar&quot;: [1, 2, 3, 4, 5],
})

dfs = spark.createDataFrame(
    [
        (&quot;a&quot;, 1),
        (&quot;b&quot;, 2),
        (&quot;c&quot;, 3),
        (&quot;d&quot;, 4),
        (&quot;d&quot;, 5),
    ],
    schema=[&quot;foo&quot;, &quot;bar&quot;],
)
</code></pre>
<h3 id="example-1-combining-head-and-sum"><a class="header" href="#example-1-combining-head-and-sum">Example 1: Combining <code>head</code> and <code>sum</code></a></h3>
<p>In <code>Polars</code> you can write something like this:</p>
<pre><code class="language-python">df.select([
    pl.col(&quot;foo&quot;).sort().head(2),
    pl.col(&quot;bar&quot;).filter(pl.col(&quot;foo&quot;) == &quot;d&quot;).sum()
])
</code></pre>
<p>Output:</p>
<pre><code>shape: (2, 2)
┌─────┬─────┐
│ foo ┆ bar │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ a   ┆ 9   │
├╌╌╌╌╌┼╌╌╌╌╌┤
│ b   ┆ 9   │
└─────┴─────┘
</code></pre>
<p>The expressions on columns <code>foo</code> and <code>bar</code> are completely independent. Since the expression on <code>bar</code> returns a single value, that value is repeated for each value output by the expression on <code>foo</code>. But <code>a</code> and <code>b</code> have no relation to the data that produced the sum of <code>9</code>.</p>
<p>To do something similar in <code>Spark</code>, you'd need to compute the sum separately and provide it as a literal:</p>
<pre><code class="language-python">from pyspark.sql.functions import col, sum, lit

bar_sum = (
    dfs
    .where(col(&quot;foo&quot;) == &quot;d&quot;)
    .groupBy()
    .agg(sum(col(&quot;bar&quot;)))
    .take(1)[0][0]
)

(
    dfs
    .orderBy(&quot;foo&quot;)
    .limit(2)
    .withColumn(&quot;bar&quot;, lit(bar_sum))
    .show()
)
</code></pre>
<p>Output:</p>
<pre><code>+---+---+
|foo|bar|
+---+---+
|  a|  9|
|  b|  9|
+---+---+
</code></pre>
<h3 id="example-2-combining-two-heads"><a class="header" href="#example-2-combining-two-heads">Example 2: Combining Two <code>head</code>s</a></h3>
<p>In <code>Polars</code> you can combine two different <code>head</code> expressions on the same DataFrame, provided that they return the same number of values.</p>
<pre><code class="language-python">df.select([
    pl.col(&quot;foo&quot;).sort().head(2),
    pl.col(&quot;bar&quot;).sort(reverse=True).head(2),
])
</code></pre>
<p>Output:</p>
<pre><code>shape: (3, 2)
┌─────┬─────┐
│ foo ┆ bar │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ a   ┆ 5   │
├╌╌╌╌╌┼╌╌╌╌╌┤
│ b   ┆ 4   │
└─────┴─────┘
</code></pre>
<p>Again, the two <code>head</code> expressions here are completely independent, and the pairing of <code>a</code> to <code>5</code> and <code>b</code> to <code>4</code> results purely from the juxtaposition of the two columns output by the expressions.</p>
<p>To accomplish something similar in <code>Spark</code>, you would need to generate an artificial key that enables you to join the values in this way.</p>
<pre><code class="language-python">from pyspark.sql import Window
from pyspark.sql.functions import row_number

foo_dfs = (
    dfs
    .withColumn(
        &quot;rownum&quot;,
        row_number().over(Window.orderBy(&quot;foo&quot;))
    )
)

bar_dfs = (
    dfs
    .withColumn(
        &quot;rownum&quot;,
        row_number().over(Window.orderBy(col(&quot;bar&quot;).desc()))
    )
)

(
    foo_dfs.alias(&quot;foo&quot;)
    .join(bar_dfs.alias(&quot;bar&quot;), on=&quot;rownum&quot;)
    .select(&quot;foo.foo&quot;, &quot;bar.bar&quot;)
    .limit(2)
    .show()
)
</code></pre>
<p>Output:</p>
<pre><code>+---+---+
|foo|bar|
+---+---+
|  a|  5|
|  b|  4|
+---+---+
</code></pre>
<h1 id="time-series"><a class="header" href="#time-series">Time Series</a></h1>
<p>For <code>time-series</code> resampling <code>Polars</code> offers a powerful API to resample data. <code>Pandas</code> is well known for
its resampling functionality via <code>df.resample</code>.</p>
<p><code>Polars</code> make the distinction between</p>
<ul>
<li>upsampling</li>
<li>downsampling</li>
</ul>
<h2 id="upsampling"><a class="header" href="#upsampling">Upsampling</a></h2>
<p>An upsample operation is actually nothing more than left joining a date range with your dataset and filling the blanks.
<code>Polars</code> provides wrapper methods for this operation. Later on we'll discuss an example.</p>
<h2 id="downsampling"><a class="header" href="#downsampling">Downsampling</a></h2>
<p>Downsampling is interesting. Here you deal with date intervals, window durations, aggregations etc.</p>
<p><code>Polars</code> views downsampling as a special case of the <strong>groupby</strong> operation and therefore has two extra entrances in the
expression API with the <code>groupby</code> context:</p>
<ul>
<li><a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.groupby_dynamic.html">groupby_dynamic</a></li>
<li><a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.groupby_rolling.html">groupby_rolling</a></li>
</ul>
<p>Calling any of those functions will give you complete access to the expression API and performance!</p>
<p>Let's go through some examples and see what that means.</p>
<h2 id="groupby-dynamic"><a class="header" href="#groupby-dynamic">Groupby Dynamic</a></h2>
<p>In the snippet below we create a <code>date range</code> with every <strong>day</strong> (<code>&quot;1d&quot;</code>) in 2021 and turn this into a <code>DataFrame</code>.</p>
<p>Then we we create dynamic windows that starts every <strong>month</strong> (<code>&quot;1mo&quot;</code>) and has a window length of <code>1</code> month. Dynamic windows
don't have a size thats fixed by the number of rows in a <code>DataFrame</code>, instead they are fixed by a temporal unit. This can
be a day (<code>&quot;1d&quot;</code>), <code>3</code> weeks (<code>&quot;3w&quot;</code>) or <code>5</code> nanoseconds (<code>&quot;5ns&quot;</code>) ... you get the idea.</p>
<p>The values that match these dynamic windows are then assigned to that group and can be aggregated with the powerful expression API.</p>
<p>Below we show an example where we use <strong>groupby_dynamic</strong> to compute:</p>
<ul>
<li>the number of days until the end of the month</li>
<li>the number of days in a month</li>
</ul>
<pre><code class="language-python">df = pl.date_range(low=datetime(2021, 1, 1), high=datetime(2021, 12, 31), interval=&quot;1d&quot;, name=&quot;time&quot;).to_frame()

out = (
    df.groupby_dynamic(&quot;time&quot;, every=&quot;1mo&quot;, period=&quot;1mo&quot;, closed=&quot;left&quot;)
    .agg(
        [
            pl.col(&quot;time&quot;).cumcount().reverse().head(3).alias(&quot;day/eom&quot;),
            ((pl.col(&quot;time&quot;) - pl.col(&quot;time&quot;).first()).last().dt.days() + 1).alias(&quot;days_in_month&quot;),
        ]
    )
    .explode(&quot;day/eom&quot;)
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (36, 3)
┌─────────────────────┬─────────┬───────────────┐
│ time                ┆ day/eom ┆ days_in_month │
│ ---                 ┆ ---     ┆ ---           │
│ datetime[ns]        ┆ u32     ┆ i64           │
╞═════════════════════╪═════════╪═══════════════╡
│ 2021-01-01 00:00:00 ┆ 30      ┆ 31            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2021-01-01 00:00:00 ┆ 29      ┆ 31            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2021-01-01 00:00:00 ┆ 28      ┆ 31            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2021-02-01 00:00:00 ┆ 27      ┆ 28            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ ...                 ┆ ...     ┆ ...           │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2021-11-01 00:00:00 ┆ 27      ┆ 30            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2021-12-01 00:00:00 ┆ 30      ┆ 31            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2021-12-01 00:00:00 ┆ 29      ┆ 31            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2021-12-01 00:00:00 ┆ 28      ┆ 31            │
└─────────────────────┴─────────┴───────────────┘
</code></pre>
<p>A dynamic window is defined by a:</p>
<ul>
<li><strong>every</strong>: indicates the interval of the window</li>
<li><strong>period</strong>: indicates the duration of the window</li>
<li><strong>offset</strong>: can be used to offset the start of the windows</li>
</ul>
<p>Because <em><strong>every</strong></em> does not have to be equal to <em><strong>period</strong></em>, we can create many groups in a very flexible way. They may overlap
or leave boundaries between them.</p>
<p>Let's see how the windows for some parameter combinations would look. Let's start out boring. 🥱</p>
<blockquote>
</blockquote>
<ul>
<li>every: 1 day -&gt; <code>&quot;1d&quot;</code></li>
<li>period: 1 day -&gt; <code>&quot;1d&quot;</code></li>
</ul>
<pre><code class="language-text">this creates adjacent windows of the same size
|--|
   |--|
      |--|
</code></pre>
<blockquote>
</blockquote>
<ul>
<li>every: 1 day -&gt; <code>&quot;1d&quot;</code></li>
<li>period: 2 days -&gt; <code>&quot;2d&quot;</code></li>
</ul>
<pre><code class="language-text">these windows have an overlap of 1 day
|----|
   |----|
      |----|
</code></pre>
<blockquote>
</blockquote>
<ul>
<li>every: 2 days -&gt; <code>&quot;2d&quot;</code></li>
<li>period: 1 day -&gt; <code>&quot;1d&quot;</code></li>
</ul>
<pre><code class="language-text">this would leave gaps between the windows
data points that in these gaps will not be a member of any group
|--|
       |--|
              |--|
</code></pre>
<h2 id="rolling-groupby"><a class="header" href="#rolling-groupby">Rolling GroupBy</a></h2>
<p>The rolling groupby is another entrance to the <code>groupby</code> context. But different from the <code>groupby_dynamic</code> the windows are
not fixed by a parameter <code>every</code> and <code>period</code>. In a rolling groupby the windows are not fixed at all! They are determined
by the values in the <code>index_column</code>.</p>
<p>So imagine having a time column with the values <code>{2021-01-01, 20210-01-05}</code> and a <code>period=&quot;5d&quot;</code> this would create the following
windows:</p>
<pre><code class="language-text">
2021-01-01   2021-01-06
    |----------|

       2021-01-05   2021-01-10
             |----------|
</code></pre>
<p>Because the windows of a rolling groupby are always determined by the values in the <code>DataFrame</code> column, the number of
groups is always equal to the original <code>DataFrame</code>.</p>
<h2 id="combining-groupby-and-dynamic--rolling"><a class="header" href="#combining-groupby-and-dynamic--rolling">Combining Groupby and Dynamic / Rolling</a></h2>
<p>Rolling and dynamic groupby's can be combined with normal groupby operations.</p>
<p>Below is an example with a dynamic groupby.</p>
<pre><code class="language-python">import polars as pl
from datetime import datetime


df = pl.DataFrame(
    {
        &quot;time&quot;: pl.date_range(
            low=datetime(2021, 12, 16),
            high=datetime(2021, 12, 16, 3),
            interval=&quot;30m&quot;,
        ),
        &quot;groups&quot;: [&quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;],
    }
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (7, 2)
┌─────────────────────┬────────┐
│ time                ┆ groups │
│ ---                 ┆ ---    │
│ datetime[ns]        ┆ str    │
╞═════════════════════╪════════╡
│ 2021-12-16 00:00:00 ┆ a      │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 2021-12-16 00:30:00 ┆ a      │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 2021-12-16 01:00:00 ┆ a      │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 2021-12-16 01:30:00 ┆ b      │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 2021-12-16 02:00:00 ┆ b      │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 2021-12-16 02:30:00 ┆ a      │
├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤
│ 2021-12-16 03:00:00 ┆ a      │
└─────────────────────┴────────┘
</code></pre>
<pre><code class="language-python">out = df.groupby_dynamic(
    &quot;time&quot;,
    every=&quot;1h&quot;,
    closed=&quot;both&quot;,
    by=&quot;groups&quot;,
    include_boundaries=True,
).agg([pl.count()])
print(out)
</code></pre>
<pre><code class="language-text">shape: (7, 5)
┌────────┬─────────────────────┬─────────────────────┬─────────────────────┬───────┐
│ groups ┆ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ count │
│ ---    ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---   │
│ str    ┆ datetime[ns]        ┆ datetime[ns]        ┆ datetime[ns]        ┆ u32   │
╞════════╪═════════════════════╪═════════════════════╪═════════════════════╪═══════╡
│ a      ┆ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 00:00:00 ┆ 1     │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ a      ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ 3     │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ a      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ 1     │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ a      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ 2     │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ a      ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 04:00:00 ┆ 2021-12-16 03:00:00 ┆ 1     │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ b      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ 2     │
├╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ b      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ 1     │
└────────┴─────────────────────┴─────────────────────┴─────────────────────┴───────┘
</code></pre>
<h2 id="upsample"><a class="header" href="#upsample">Upsample</a></h2>
<blockquote>
<p>This content is under construction.</p>
</blockquote>
<h1 id="how-can-i"><a class="header" href="#how-can-i">How can I?</a></h1>
<p>This chapter contains some snippets that will get you up to speed with the most
idiomatic way to get things done in <code>Polars</code>.</p>
<blockquote>
<p>The How can I chapter is under construction.</p>
</blockquote>
<h1 id="io"><a class="header" href="#io">IO</a></h1>
<p><code>Polars</code> supports different file types, and its respective parsers are amongst the fastest
out there.</p>
<p>For instance, it is faster to load a CSV file <em>via</em> <code>Polars</code> before handing it to <code>Pandas</code>
than loading them using <code>Pandas</code>. Just run a
<code>pl.read_csv(&quot;&lt;FILE&gt;&quot;, rechunk=False).to_pandas()</code> to convince yourself!</p>
<h1 id="character-separated-values"><a class="header" href="#character-separated-values">Character-Separated Values</a></h1>
<h2 id="read--write"><a class="header" href="#read--write">Read &amp; Write</a></h2>
<p>Reading a CSV file should look familiar:</p>
<pre><code class="language-python">df = pl.read_csv(&quot;path.csv&quot;)
</code></pre>
<p>CSV files come in many different flavors, so make sure to check the
<a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.read_csv.html"><code>read_csv()</code></a> API.</p>
<p>Writing to a CSV file can be done with the
<a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.write_csv.html"><code>write_csv()</code></a> method.</p>
<pre><code class="language-python">df = pl.DataFrame({&quot;foo&quot;: [1, 2, 3], &quot;bar&quot;: [None, &quot;bak&quot;, &quot;baz&quot;]})
df.write_csv(&quot;path.csv&quot;)
</code></pre>
<h2 id="scan"><a class="header" href="#scan">Scan</a></h2>
<p><code>Polars</code> allows you to <em>scan</em> a CSV input. Scanning delays the actual parsing of the file
and instead returns a lazy computation holder called a <code>LazyFrame</code>.</p>
<pre><code class="language-python">df = pl.scan_csv(&quot;path.csv&quot;)
</code></pre>
<p>If you want to know why this is desirable,
you can read more about those <code>Polars</code> optimizations <a href="howcani/io/../../optimizations/intro.html">here</a>.</p>
<h1 id="parquet"><a class="header" href="#parquet">Parquet</a></h1>
<p>Loading or writing <a href="https://parquet.apache.org/"><code>Parquet</code> files</a> is lightning fast.
<code>Pandas</code> uses <a href="https://arrow.apache.org/docs/python/"><code>PyArrow</code></a> -<code>Python</code> bindings
exposed by <code>Arrow</code>- to load <code>Parquet</code> files into memory, but it has to copy that data into
<code>Pandas</code> memory. With <code>Polars</code> there is no extra cost due to
copying as we read <code>Parquet</code> directly into <code>Arrow</code> memory and <em>keep it there</em>.</p>
<h2 id="read--write-1"><a class="header" href="#read--write-1">Read &amp; write</a></h2>
<pre><code class="language-python">df = pl.read_parquet(&quot;path.parquet&quot;)
</code></pre>
<pre><code class="language-python">df = pl.DataFrame({&quot;foo&quot;: [1, 2, 3], &quot;bar&quot;: [None, &quot;bak&quot;, &quot;baz&quot;]})
df.write_parquet(&quot;path.parquet&quot;)
</code></pre>
<h2 id="scan-1"><a class="header" href="#scan-1">Scan</a></h2>
<p><code>Polars</code> allows you to <em>scan</em> a <code>Parquet</code> input. Scanning delays the actual parsing of the
file and instead returns a lazy computation holder called a <code>LazyFrame</code>.</p>
<pre><code class="language-python">df = pl.scan_parquet(&quot;path.parquet&quot;)
</code></pre>
<p>If you want to know why this is desirable,
you can read more about those <code>Polars</code> optimizations <a href="howcani/io/../../optimizations/intro.html">here</a>.</p>
<h2 id="dealing-with-multiple-files"><a class="header" href="#dealing-with-multiple-files">Dealing with multiple files.</a></h2>
<p><code>Polars</code> can deal with multiple files differently depending on your needs and memory strain.</p>
<p>Let's create some files to give use some context:</p>
<pre><code class="language-python">import polars as pl

df = pl.DataFrame({&quot;foo&quot;: [1, 2, 3], &quot;bar&quot;: [None, &quot;ham&quot;, &quot;spam&quot;]})

for i in range(5):
    df.write_csv(f&quot;my_many_files_{i}.csv&quot;)
</code></pre>
<h2 id="reading-into-a-single-dataframe"><a class="header" href="#reading-into-a-single-dataframe">Reading into a single <code>DataFrame</code></a></h2>
<p>To read multiple files into a single <code>DataFrame</code>, we can use globbing patterns:</p>
<pre><code class="language-python">df = pl.read_csv(&quot;my_many_files_*.csv&quot;)
print(df)
</code></pre>
<pre><code class="language-text">shape: (15, 2)
┌─────┬──────┐
│ foo ┆ bar  │
│ --- ┆ ---  │
│ i64 ┆ str  │
╞═════╪══════╡
│ 1   ┆ null │
├╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 2   ┆ ham  │
├╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 3   ┆ spam │
├╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 1   ┆ null │
├╌╌╌╌╌┼╌╌╌╌╌╌┤
│ ... ┆ ...  │
├╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 3   ┆ spam │
├╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 1   ┆ null │
├╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 2   ┆ ham  │
├╌╌╌╌╌┼╌╌╌╌╌╌┤
│ 3   ┆ spam │
└─────┴──────┘
</code></pre>
<p>To see how this works we can take a look at the query plan. Below we see that all files are read separately and
concatenated into a single <code>DataFrame</code>. <code>Polars</code> will try to parallelize the reading.</p>
<pre><code class="language-python">pl.scan_csv(&quot;my_many_files_*.csv&quot;).show_graph()
</code></pre>
<p><img src="multiple_files/../outputs/multiple_files/single_df_graph.png" alt="single_df_graph" /></p>
<h2 id="reading-and-processing-in-parallel"><a class="header" href="#reading-and-processing-in-parallel">Reading and processing in parallel</a></h2>
<p>If your files don't have to be in a single table you can also build a query plan for each file and execute them in paralllel
on the <code>Polars</code> thread pool.</p>
<p>All query plan execution is embarrassingly parallel and doesn't require any communication.</p>
<pre><code class="language-python">import polars as pl
import glob

queries = []
for file in glob.glob(&quot;my_many_files_*.csv&quot;):
    q = pl.scan_csv(file).groupby(&quot;bar&quot;).agg([pl.count(), pl.sum(&quot;foo&quot;)])
    queries.append(q)

dataframes = pl.collect_all(queries)
print(dataframes)
</code></pre>
<pre><code class="language-text">[shape: (3, 3)
┌──────┬───────┬─────┐
│ bar  ┆ count ┆ foo │
│ ---  ┆ ---   ┆ --- │
│ str  ┆ u32   ┆ i64 │
╞══════╪═══════╪═════╡
│ ham  ┆ 1     ┆ 2   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ null ┆ 1     ┆ 1   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ spam ┆ 1     ┆ 3   │
└──────┴───────┴─────┘, shape: (3, 3)
┌──────┬───────┬─────┐
│ bar  ┆ count ┆ foo │
│ ---  ┆ ---   ┆ --- │
│ str  ┆ u32   ┆ i64 │
╞══════╪═══════╪═════╡
│ spam ┆ 1     ┆ 3   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ null ┆ 1     ┆ 1   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ ham  ┆ 1     ┆ 2   │
└──────┴───────┴─────┘, shape: (3, 3)
┌──────┬───────┬─────┐
│ bar  ┆ count ┆ foo │
│ ---  ┆ ---   ┆ --- │
│ str  ┆ u32   ┆ i64 │
╞══════╪═══════╪═════╡
│ null ┆ 1     ┆ 1   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ ham  ┆ 1     ┆ 2   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ spam ┆ 1     ┆ 3   │
└──────┴───────┴─────┘, shape: (3, 3)
┌──────┬───────┬─────┐
│ bar  ┆ count ┆ foo │
│ ---  ┆ ---   ┆ --- │
│ str  ┆ u32   ┆ i64 │
╞══════╪═══════╪═════╡
│ null ┆ 1     ┆ 1   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ spam ┆ 1     ┆ 3   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ ham  ┆ 1     ┆ 2   │
└──────┴───────┴─────┘, shape: (3, 3)
┌──────┬───────┬─────┐
│ bar  ┆ count ┆ foo │
│ ---  ┆ ---   ┆ --- │
│ str  ┆ u32   ┆ i64 │
╞══════╪═══════╪═════╡
│ spam ┆ 1     ┆ 3   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ ham  ┆ 1     ┆ 2   │
├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌┤
│ null ┆ 1     ┆ 1   │
└──────┴───────┴─────┘]
</code></pre>
<h1 id="read-from-mysql-postgres-sqlite-redshift-clickhouse"><a class="header" href="#read-from-mysql-postgres-sqlite-redshift-clickhouse">Read from MySQL, Postgres, Sqlite, Redshift, Clickhouse</a></h1>
<p>To read from one of the supported databases <code>connector-x</code> needs to be installed.</p>
<pre><code class="language-shell">$  pip install connectorx&gt;=0.2.0a3
</code></pre>
<pre><code class="language-python">import polars as pl

conn = &quot;postgres://username:password@server:port/database&quot;
query = &quot;SELECT * FROM foo&quot;

pl.read_sql(query, conn)
</code></pre>
<h1 id="interact-with-aws"><a class="header" href="#interact-with-aws">Interact with AWS</a></h1>
<blockquote>
<p>The Interact with AWS page is under construction.</p>
</blockquote>
<p>To read from or write to an AWS bucket, additional dependencies are needed:</p>
<pre><code class="language-shell">$ pip install s3fs
</code></pre>
<p>In the next few snippets we'll demonstrate interacting with a <code>Parquet</code> file
located on an AWS bucket.</p>
<h2 id="read"><a class="header" href="#read">Read</a></h2>
<p>Load a <code>.parquet</code> file using:</p>
<pre><code class="language-python">import polars as pl
import pyarrow.parquet as pq
import s3fs

fs = s3fs.S3FileSystem()
bucket = &quot;&lt;YOUR_BUCKET&gt;&quot;
path = &quot;&lt;YOUR_PATH&gt;&quot;

dataset = pq.ParquetDataset(f&quot;s3://{bucket}/{path}&quot;, filesystem=fs)
df = pl.from_arrow(dataset.read())
</code></pre>
<h2 id="write"><a class="header" href="#write">Write</a></h2>
<blockquote>
<p>This content is under construction.</p>
</blockquote>
<h1 id="interact-with-google-bigquery"><a class="header" href="#interact-with-google-bigquery">Interact with Google BigQuery</a></h1>
<p>To read or write from GBQ, additional dependencies are needed:</p>
<pre><code class="language-shell">$ pip install google-cloud-bigquery
</code></pre>
<h2 id="read-1"><a class="header" href="#read-1">Read</a></h2>
<p>We can load a query into a <code>DataFrame</code> like this:</p>
<pre><code class="language-python">import polars as pl
from google.cloud import bigquery

client = bigquery.Client()

# Perform a query.
QUERY = (
    'SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` '
    'WHERE state = &quot;TX&quot; '
    'LIMIT 100')
query_job = client.query(QUERY)  # API request
rows = query_job.result()  # Waits for query to finish

df = pl.from_arrow(rows.to_arrow())
</code></pre>
<h2 id="write-1"><a class="header" href="#write-1">Write</a></h2>
<blockquote>
<p>This content is under construction.</p>
</blockquote>
<h1 id="interact-with-postgres"><a class="header" href="#interact-with-postgres">Interact with Postgres</a></h1>
<h2 id="read-2"><a class="header" href="#read-2">Read</a></h2>
<p>To read from postgres, additional dependencies are needed:</p>
<pre><code class="language-shell">$  pip install connectorx&gt;=0.2.0a3
</code></pre>
<pre><code class="language-python">import polars as pl

conn = &quot;postgresql://username:password@server:port/database&quot;
query = &quot;SELECT * FROM foo&quot;

pl.read_sql(query, conn)
</code></pre>
<h2 id="write-2"><a class="header" href="#write-2">Write</a></h2>
<p>To write to postgres, additional dependencies are needed:</p>
<pre><code class="language-shell">$ pip install psycopg2-binary
</code></pre>
<p>For writing to a postgres database with <code>psycopg2</code>, we utilize <code>execute_batch</code>. This will limit round trips needed
to the server.</p>
<p>We first make sure that all our dtypes are in a format that <code>psycopg2</code> recognizes, and then we use <code>DataFrame.rows</code> to
easily transform the columnar data to rows that the database driver can work with.</p>
<pre><code class="language-python">from psycopg2 import sql
import psycopg2.extras
import polars as pl

# let's assume we have a DataFrame with some floats, integers, strings, and date64 columns.
df = pl.read_parquet(&quot;somefile.parquet&quot;)

# first me convert polars date64 representation to python datetime objects 
for col in df:
    # only for date64
    if col.dtype == pl.Date64:
        df = df.with_column(col.dt.to_python_datetime())

# create sql identifiers for the column names
# we do this to safely insert this into a sql query
columns = sql.SQL(&quot;,&quot;).join(sql.Identifier(name) for name in df.columns)

# create placeholders for the values. These will be filled later
values = sql.SQL(&quot;,&quot;).join([sql.Placeholder() for _ in df.columns])

table_id = &quot;mytable&quot;

# prepare the insert query
insert_stmt = sql.SQL(&quot;INSERT INTO ({}) VALUES({});&quot;).format(
    sql.Identifier(table_id), columns, values
)

# make a connection
conn = psycopg2.connect()
cur = conn.cursort()

# do the insert
psycopg2.extras.execute_batch(cur, insert_stmt, df.rows())
conn.commit()
</code></pre>
<h1 id="interoperability"><a class="header" href="#interoperability">Interoperability</a></h1>
<h1 id="arrow"><a class="header" href="#arrow">Arrow</a></h1>
<p><code>Arrow</code> is rapidly becoming the <em>de facto</em> standard for columnar data. This means that
support for <code>Arrow</code> is growing rapidly (both languages and tools). Due to the amazing
effort behind the format, using <code>Arrow</code> is now likely the fastest way to:</p>
<ul>
<li>Read and write <code>Parquet</code> formatted files</li>
<li>Read CSV into columnar data</li>
<li>Exchanging columnar data</li>
</ul>
<p><code>Polars</code> uses an <code>Arrow</code> memory buffer as the most basic building block for the <code>Polars</code>
<code>Series</code>. This means that we exchange data between <code>Polars</code> and <code>Arrow</code> <strong>without
copying</strong> it. It also means that <code>Polars</code> shares the same performance gains that <code>Arrow</code> receives.</p>
<p>Convert a <code>Polars</code> <code>DataFrame</code> or <code>Series</code> to <code>Arrow</code> using the <code>.to_arrow()</code>
method. Similarly, importing from <code>Arrow</code> data structure can be performed with the
<code>.from_arrow()</code> functions.</p>
<h1 id="numpy"><a class="header" href="#numpy">NumPy</a></h1>
<p><code>Polars</code> <code>Series</code> have support for <code>NumPy</code>
<a href="https://numpy.org/doc/stable/reference/ufuncs.html">universal functions (ufuncs)</a>.
Element-wise functions such as <code>np.exp()</code>, <code>np.cos()</code>, <code>np.div()</code>, <em>etc.</em> all work with
almost zero overhead.</p>
<p>However, as a <code>Polars</code>-specific remark: missing values are a separate bitmask and are not
visible by <code>NumPy</code>. It can yield to a window function or a <code>np.convolve()</code> giving
flawed or incomplete results.</p>
<p>Convert a <code>Polars</code> <code>Series</code> to a <code>NumPy</code> array with the <code>.to_numpy()</code> method.
Missing values will be replaced by <code>np.nan</code> during the conversion. If the <code>Series</code> does
not include missing values, or those values are not desired anymore, the <code>.view()</code>
method can be used instead, providing a zero-copy <code>NumPy</code> array of the data.</p>
<h1 id="data-handling"><a class="header" href="#data-handling">Data handling</a></h1>
<h1 id="process-strings"><a class="header" href="#process-strings">Process strings</a></h1>
<p>Thanks to its <code>Arrow</code> backend, <code>Polars</code> string operations are much faster compared to the
same operations performed with <code>NumPy</code> or <code>Pandas</code>. In the latter, strings are stored as
<code>Python</code> objects. While traversing the <code>np.array</code> or the <code>pd.Series</code> the CPU needs to
follow all the string pointers, and jump to many random memory locations -- which
is very cache-inefficient. In <code>Polars</code> (via the <code>Arrow</code> data
structure) strings are contiguous in memory. Thus traversing is cache-optimal and
predictable for the CPU.</p>
<p>The string processing functions available in <code>Polars</code> are available in the
<a href="https://pola-rs.github.io/polars/py-polars/html/reference/series.html#strings"><code>str</code> namespace</a>.</p>
<p>Below are a few examples. To compute string lengths:</p>
<pre><code class="language-python">import polars as pl

df = pl.DataFrame({&quot;shakespeare&quot;: &quot;All that glitters is not gold&quot;.split(&quot; &quot;)})

df = df.with_column(pl.col(&quot;shakespeare&quot;).str.lengths().alias(&quot;letter_count&quot;))
</code></pre>
<p>returning:</p>
<pre><code class="language-text">shape: (6, 2)
┌─────────────┬──────────────┐
│ shakespeare ┆ letter_count │
│ ---         ┆ ---          │
│ str         ┆ u32          │
╞═════════════╪══════════════╡
│ All         ┆ 3            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ that        ┆ 4            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ glitters    ┆ 8            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ is          ┆ 2            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ not         ┆ 3            │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ gold        ┆ 4            │
└─────────────┴──────────────┘
</code></pre>
<p>And below a regex pattern to filter out articles (<code>the</code>, <code>a</code>, <code>and</code>, <em>etc.</em>) from a
sentence:</p>
<pre><code class="language-python">import polars as pl

df = pl.DataFrame({&quot;a&quot;: &quot;The man that ate a whole cake&quot;.split(&quot; &quot;)})

df = df.filter(pl.col(&quot;a&quot;).str.contains(r&quot;(?i)^the$|^a$&quot;).is_not())
</code></pre>
<p>yielding:</p>
<pre><code class="language-text">shape: (5, 1)
┌───────┐
│ a     │
│ ---   │
│ str   │
╞═══════╡
│ man   │
├╌╌╌╌╌╌╌┤
│ that  │
├╌╌╌╌╌╌╌┤
│ ate   │
├╌╌╌╌╌╌╌┤
│ whole │
├╌╌╌╌╌╌╌┤
│ cake  │
└───────┘
</code></pre>
<h1 id="timestamp-parsing"><a class="header" href="#timestamp-parsing">Timestamp parsing</a></h1>
<p><code>Polars</code> offers <code>4</code> time datatypes:</p>
<ul>
<li><code>pl.Date</code>, to be used for <strong>date</strong> objects: the number of days since the UNIX epoch as
a 32 bit signed integer.</li>
<li><code>pl.Datetime</code>, to be used of <strong>datetime</strong> ojects: the number of nanoseconds since the
UNIX epoch as a 64 bit signed integer.</li>
<li><code>pl.Time</code>, encoded as the number of nanoseconds since midnight.</li>
</ul>
<p><code>Polars</code> string (<code>pl.Utf8</code>) datatypes can be parsed as either of them. You can let
<code>Polars</code> try to guess the format of the date[time], or explicitly provide a <code>fmt</code>
rule.</p>
<p>For instance (check <a href="https://strftime.org/">this link</a> for an comprehensive list):</p>
<ul>
<li><code>&quot;%Y-%m-%d&quot;</code> for <code>&quot;2020-12-31&quot;</code></li>
<li><code>&quot;%Y/%B/%d&quot;</code> for <code>&quot;2020/December/31&quot;</code></li>
<li><code>&quot;%B %y&quot;</code> for <code>&quot;December 20&quot;</code></li>
</ul>
<p>Below a quick example:</p>
<pre><code class="language-python">import polars as pl

dataset = pl.DataFrame({&quot;date&quot;: [&quot;2020-01-02&quot;, &quot;2020-01-03&quot;, &quot;2020-01-04&quot;], &quot;index&quot;: [1, 2, 3]})

q = dataset.lazy().with_column(pl.col(&quot;date&quot;).str.strptime(pl.Date, &quot;%Y-%m-%d&quot;))

df = q.collect()
</code></pre>
<p>returning:</p>
<pre><code class="language-text">shape: (3, 2)
┌────────────┬───────┐
│ date       ┆ index │
│ ---        ┆ ---   │
│ date       ┆ i64   │
╞════════════╪═══════╡
│ 2020-01-02 ┆ 1     │
├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ 2020-01-03 ┆ 2     │
├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤
│ 2020-01-04 ┆ 3     │
└────────────┴───────┘
</code></pre>
<p>All datetime functionality is shown in the <a href="https://pola-rs.github.io/polars/py-polars/html/reference/series.html#timeseries"><code>dt</code> namespace</a>.</p>
<h1 id="performance"><a class="header" href="#performance">Performance</a></h1>
<p>This chapter handles some gotcha's needed to squeeze maximum performance out of <code>Polars</code>.
When used properly, <code>Polars</code> can run at blazing speeds. Take a look at the results in
<a href="https://h2oai.github.io/db-benchmark/">H2O AI database benchmark</a>.</p>
<h1 id="strings"><a class="header" href="#strings">Strings</a></h1>
<p>Understanding the memory format used by <code>Arrow</code> and <code>Polars</code> can really increase performance
of your queries. This is especially true for large string data. The figure below shows
how an <code>Arrow</code> <code>UTF8</code> array is laid out in memory.</p>
<p>The array <code>[&quot;foo&quot;, &quot;bar&quot;, &quot;ham&quot;]</code> is encoded by :</p>
<ul>
<li>a concatenated string <code>&quot;foobarham&quot;</code>,</li>
<li>an offset array indicating the start (and end) of each string <code>[0, 2, 5, 8]</code>,</li>
<li>a null bitmap, indicating null values.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/arrow-string.svg" alt="" /></p>
<p>This memory structure is very cache-efficient if we are to read the string values.
Especially if we compare it to a <code>Vec&lt;String&gt;</code> (an array of heap allocated string data
in <code>Rust</code>).</p>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/pandas-string.svg" alt="" /></p>
<p>However, if we need to reorder the <code>Arrow</code> <code>UTF8</code> array, we need to swap around all the
bytes of the string values, which can become very expensive when dealing with large
strings. On the other hand for <code>Vec&lt;String&gt;</code>, we only need to swap pointers around,
which is only 8 bytes data that have to be moved with little cost.</p>
<p>Reordering a <code>DataFrame</code> embedding a large number of <code>Utf8</code> <code>Series</code> due to an operation
(filtering, joining, grouping, <em>etc.</em>) can quickly become quite expensive.</p>
<h2 id="categorical-type"><a class="header" href="#categorical-type">Categorical type</a></h2>
<p>For this reason <code>Polars</code> has a <code>CategoricalType</code>. A <code>Categorical</code> <code>Series</code> is an array
filled with <code>u32</code> values that each represent a unique string value. Thereby maintaining
cache efficiency whilst remaining cheap to move values around.</p>
<p>In the example below we demonstrate how you can cast a <code>Utf8</code> <code>Series</code> column to a
<code>Categorical</code> <code>Series</code>.</p>
<pre><code class="language-python">import polars as pl

df[&quot;utf8-column&quot;].cast(pl.Categorical)
</code></pre>
<h3 id="eager-join-multiple-dataframes-on-categorical-data"><a class="header" href="#eager-join-multiple-dataframes-on-categorical-data">Eager join multiple DataFrames on Categorical data</a></h3>
<p>When two <code>DataFrames</code> need to be joined based on string data the <code>Categorical</code> data needs
to be synchronized (data in column <code>A</code> of <code>df1</code> needs to point to the same underlying
string data as column <code>B</code> in <code>df2</code>). One can do so by casting data in the <code>StringCache</code>
context manager. This will synchronize all discoverable string values for the duration of that
context manager. If you want the global string cache to exist during the whole
run, you can set <code>toggle_string_cache</code> to <code>True</code>.</p>
<pre><code class="language-python">import polars as pl

df1 = pl.DataFrame({&quot;a&quot;: [&quot;foo&quot;, &quot;bar&quot;, &quot;ham&quot;], &quot;b&quot;: [1, 2, 3]})
df2 = pl.DataFrame({&quot;a&quot;: [&quot;foo&quot;, &quot;spam&quot;, &quot;eggs&quot;], &quot;c&quot;: [3, 2, 2]})

with pl.StringCache():
    df1.with_column(pl.col(&quot;a&quot;).cast(pl.Categorical))
    df2.with_column(pl.col(&quot;a&quot;).cast(pl.Categorical))
</code></pre>
<h3 id="lazy-join-multiple-dataframes-on-categorical-data"><a class="header" href="#lazy-join-multiple-dataframes-on-categorical-data">Lazy join multiple DataFrames on Categorical data</a></h3>
<p>A lazy query always has a global string cache (unless you opt-out) for the duration of
that query (until <code>.collect()</code> is called). The example below shows how you could join
two <code>DataFrames</code> with <code>Categorical</code> types.</p>
<pre><code class="language-python">import polars as pl

lf1 = pl.DataFrame({&quot;a&quot;: [&quot;foo&quot;, &quot;bar&quot;, &quot;ham&quot;], &quot;b&quot;: [1, 2, 3]}).lazy()
lf2 = pl.DataFrame({&quot;a&quot;: [&quot;foo&quot;, &quot;spam&quot;, &quot;eggs&quot;], &quot;c&quot;: [3, 2, 2]}).lazy()

lf1 = lf1.with_column(pl.col(&quot;a&quot;).cast(pl.Categorical))
lf2 = lf2.with_column(pl.col(&quot;a&quot;).cast(pl.Categorical))

lf1.join(lf2, on=&quot;a&quot;, how=&quot;inner&quot;)
</code></pre>
<h1 id="optimizations"><a class="header" href="#optimizations">Optimizations</a></h1>
<p>This chapter will investigate some of the optimizations that are applied by the <code>Polars</code>
query optimizer by going through some examples to see how <code>Polars</code> modifies the original query plan.</p>
<h1 id="lazy-api-1"><a class="header" href="#lazy-api-1">Lazy API</a></h1>
<blockquote>
<p>The Lazy API page is under construction.</p>
</blockquote>
<p>To demonstrate the lazy <code>Polars</code> capabilities we'll explore two medium-large
datasets of usernames:</p>
<p><a href="https://www.reddit.com/r/datasets/comments/9i8s5j/dataset_metadata_for_69_million_reddit_users_in/">Reddit usernames dataset</a>
containing 69+ million rows</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

dataset = pl.read_csv(f&quot;{DATA_DIR}/reddit.csv&quot;, stop_after_n_rows=10)
</code></pre>
<pre><code class="language-text">shape: (5, 6)
┌─────┬──────────────────────────┬─────────────┬────────────┬───────────────┬────────────┐
│ id  ┆ name                     ┆ created_utc ┆ updated_on ┆ comment_karma ┆ link_karma │
│ --- ┆ ---                      ┆ ---         ┆ ---        ┆ ---           ┆ ---        │
│ i64 ┆ str                      ┆ i64         ┆ i64        ┆ i64           ┆ i64        │
╞═════╪══════════════════════════╪═════════════╪════════════╪═══════════════╪════════════╡
│ 1   ┆ truman48lamb_jasonbroken ┆ 1397113470  ┆ 1536527864 ┆ 0             ┆ 0          │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 2   ┆ johnethen06_jasonbroken  ┆ 1397113483  ┆ 1536527864 ┆ 0             ┆ 0          │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 3   ┆ yaseinrez_jasonbroken    ┆ 1397113483  ┆ 1536527864 ┆ 0             ┆ 1          │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 4   ┆ Valve92_jasonbroken      ┆ 1397113503  ┆ 1536527864 ┆ 0             ┆ 0          │
├╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 5   ┆ srbhuyan_jasonbroken     ┆ 1397113506  ┆ 1536527864 ┆ 0             ┆ 0          │
└─────┴──────────────────────────┴─────────────┴────────────┴───────────────┴────────────┘
</code></pre>
<p>and the <a href="https://github.com/RuneStar/name-cleanup-2014">Runescape username dataset</a>
containing about 55+ million records.</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

dataset = pl.read_csv(f&quot;{DATA_DIR}/runescape.csv&quot;, has_headers=False, stop_after_n_rows=10)
</code></pre>
<pre><code class="language-text">shape: (5, 1)
┌─────────────┐
│ column_1    │
│ ---         │
│ str         │
╞═════════════╡
│ a000        │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ a0000       │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ a000000     │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ a0000000    │
├╌╌╌╌╌╌╌╌╌╌╌╌╌┤
│ a0000000000 │
└─────────────┘
</code></pre>
<h1 id="predicate-pushdown"><a class="header" href="#predicate-pushdown">Predicate pushdown</a></h1>
<blockquote>
<p>The Predicate pushdown page is under construction</p>
</blockquote>
<p>Predicate pushdown is an optimization <code>Polars</code> does that reduces query times and memory
usage. A predicate is database jargon for applying a filter on some table, thereby
reducing the number of rows on that table.</p>
<p>So let's see if we can load some Reddit data and filter on a few predicates.</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

q1 = (
    pl.scan_csv(f&quot;{DATA_DIR}/reddit.csv&quot;)
    .filter(pl.col(&quot;comment_karma&quot;) &gt; 0)
    .filter(pl.col(&quot;link_karma&quot;) &gt; 0)
    .filter(pl.col(&quot;name&quot;).str.contains(r&quot;^a&quot;))  # filter name that start with an &quot;a&quot;
)
</code></pre>
<p>If we were to run this query above nothing would happen! This is due to the lazy evaluation.
Nothing will happen until specifically requested. This allows Polars to see the whole
context of a query and optimize just in time for execution.</p>
<p>Execution is requested by the <code>.collect</code> method. This would query all available data.
While you're writing, optimizing, and checking your query, this is often undesirable. Another
method that calls for execution is the <code>.fetch</code> method. <code>.fetch</code> takes a parameter
<code>n_rows</code> and tries to 'fetch' that number of rows at the data source (no guarantees are
given though).</p>
<p>So let's &quot;fetch&quot; ~10 Million rows from the source file and apply the predicates.</p>
<pre><code class="language-python">q1.fetch(n_rows=int(1e7))
</code></pre>
<pre><code class="language-text">shape: (656, 6)
┌─────────┬─────────────┬─────────────┬────────────┬───────────────┬────────────┐
│ id      ┆ name        ┆ created_utc ┆ updated_on ┆ comment_karma ┆ link_karma │
│ ---     ┆ ---         ┆ ---         ┆ ---        ┆ ---           ┆ ---        │
│ i64     ┆ str         ┆ i64         ┆ i64        ┆ i64           ┆ i64        │
╞═════════╪═════════════╪═════════════╪════════════╪═══════════════╪════════════╡
│ 77860   ┆ aquarin     ┆ 1137474000  ┆ 1536528294 ┆ 150           ┆ 11         │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 77974   ┆ aadvaark    ┆ 1137301200  ┆ 1536528294 ┆ 26            ┆ 47         │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 78004   ┆ apoisel     ┆ 1137301200  ┆ 1536497404 ┆ 42            ┆ 2549       │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 78041   ┆ aonic       ┆ 1137301200  ┆ 1536497404 ┆ 2931          ┆ 2095       │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ ...     ┆ ...         ┆ ...         ┆ ...        ┆ ...           ┆ ...        │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 1192656 ┆ atothedrian ┆ 1162785880  ┆ 1536497412 ┆ 748           ┆ 585        │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 1204607 ┆ akbusiness  ┆ 1162899425  ┆ 1536532995 ┆ 73            ┆ 512        │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 1214809 ┆ aaminics    ┆ 1162969322  ┆ 1536533034 ┆ 22            ┆ 6          │
├╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤
│ 1225341 ┆ antonulrich ┆ 1163110623  ┆ 1536497412 ┆ 9304          ┆ 1782       │
└─────────┴─────────────┴─────────────┴────────────┴───────────────┴────────────┘
</code></pre>
<p>Above we see that from the 10 Million rows, 61503 rows match our predicate.</p>
<h2 id="break-it-down"><a class="header" href="#break-it-down">Break it down</a></h2>
<p>In <code>Polars</code> we can visualize the query plan. Let's take a look.</p>
<pre><code class="language-python">q1.show_graph(optimized=False)
</code></pre>
<p><img src="optimizations/lazy/../../outputs/predicate_pushdown/graph1.png" alt="" /></p>
<p>The astute reader maybe would notice that our query is not very optimal because we have
three separate <em>FILTER</em> nodes. That means that after every <em>FILTER</em> a new <code>DataFrame</code> is
allocated, which will be input to the next <em>FILTER</em> and then deleted from memory -- that
must be redundant, and you know what... they'd be right. The predicates should be
combined. We should have written this query:</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

q2 = pl.scan_csv(f&quot;{DATA_DIR}/reddit.csv&quot;).filter(
    (pl.col(&quot;comment_karma&quot;) &gt; 0) &amp; (pl.col(&quot;link_karma&quot;) &gt; 0) &amp; (pl.col(&quot;name&quot;).str.contains(r&quot;^a&quot;))
)
</code></pre>
<p>That would translate to:</p>
<pre><code class="language-python">q2.show_graph(optimized=False)
</code></pre>
<p><img src="optimizations/lazy/../../outputs/predicate_pushdown/graph2.png" alt="" /></p>
<p>As we can see the predicates are combined. This would lead to less copying of data.</p>
<h2 id="in-comes-optimization"><a class="header" href="#in-comes-optimization">In comes optimization</a></h2>
<p><code>Polars</code> tries to save that mental overhead from the query writer and combines predicates
for you. Besides that, it pushes predicates down to the scan level! Let's see how our
optimized query looks.</p>
<pre><code class="language-python">q1.show_graph(optimized=True)
</code></pre>
<p><img src="optimizations/lazy/../../outputs/predicate_pushdown/graph1-optimized.png" alt="" /></p>
<p>It may be hard to see, but what is clear is that there is only a single node: the <em>CSV
SCAN</em>. The predicate filtering is done during the reading of the csv. This means that
this query's memory overhead is reduced by filtering factor! This makes a huge impact.</p>
<h3 id="memory"><a class="header" href="#memory">Memory</a></h3>
<p>As we have seen there were ~ 62,000 rows left after the <em>FILTER</em>. That means that (aside
for some memory overhead of the batch size and filter operations) we use \(
\frac{6.2\text{e-}4}{1\text{e-}7} \sim 0.6 \text{%} \) of the memory we would
during an eager evaluation where we first would read the whole table in memory before
applying a filter.</p>
<h3 id="performance-1"><a class="header" href="#performance-1">Performance</a></h3>
<p>At the time of writing this, the predicate pushdown also increased the query time
performance.</p>
<p><strong>Without optimization</strong>, <code>predicate_pushdown=False</code> flag:</p>
<pre><code class="language-text">real	0m2,401s
user	0m5,457s
sys	0m0,894s
</code></pre>
<p><strong>With optimization</strong>, <code>predicate_pushdown=True</code> flag:</p>
<pre><code class="language-text">real	0m1,597s
user	0m6,143s
sys	0m0,647s
</code></pre>
<h2 id="relational-algebra"><a class="header" href="#relational-algebra">Relational algebra</a></h2>
<p>In the visualization of the query plan, you see a \( \sigma \) symbol. This indicates
a predicate done at the <em>SCAN</em> level. There is also a \( \pi \) symbol indicating
projection (database jargon for column selection), but we'll get to that later.</p>
<h2 id="cheaper-joins"><a class="header" href="#cheaper-joins">Cheaper joins</a></h2>
<p>Predicate pushdown optimization will generally also lead to cheaper join's. A join is
an expensive operation. The fewer rows we have in a join operation the cheaper
it will become.</p>
<h1 id="projection-pushdown"><a class="header" href="#projection-pushdown">Projection pushdown</a></h1>
<blockquote>
<p>The Projection pushdown page is under construction.</p>
</blockquote>
<p>Let's expand our query from the previous section by joining the result of the <em>FILTER</em>
operation with the runescape data to find popular Reddit usernames that have a
username starting with an <code>&quot;a&quot;</code> that also played Runescape. That must be something we are all
interested in!</p>
<p>The query would look like this:</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

reddit = (
    pl.scan_csv(f&quot;{DATA_DIR}/reddit.csv&quot;)
    .filter(pl.col(&quot;comment_karma&quot;) &gt; 0)
    .filter(pl.col(&quot;link_karma&quot;) &gt; 0)
    .filter(pl.col(&quot;name&quot;).str.contains(r&quot;^a&quot;))
)

runescape = pl.scan_csv(&quot;data/runescape.csv&quot;, has_headers=False).select(pl.col(&quot;column_1&quot;).alias(&quot;name&quot;))

dataset = reddit.join(runescape, on=&quot;name&quot;, how=&quot;inner&quot;).select([&quot;name&quot;, &quot;comment_karma&quot;, &quot;link_karma&quot;])

df1 = dataset.fetch(int(1e7))
df2 = dataset.fetch(int(1e7), predicate_pushdown=True, projection_pushdown=True)
</code></pre>
<p>And yields the following DataFrame.</p>
<pre><code class="language-text">shape: (0, 3)
┌──────┬───────────────┬────────────┐
│ name ┆ comment_karma ┆ link_karma │
│ ---  ┆ ---           ┆ ---        │
│ str  ┆ i64           ┆ i64        │
╞══════╪═══════════════╪════════════╡
└──────┴───────────────┴────────────┘
</code></pre>
<h2 id="break-it-down-1"><a class="header" href="#break-it-down-1">Break it down</a></h2>
<p>Again, let's take a look the query plan.</p>
<pre><code class="language-python">dataset.show_graph(optimized=False)
</code></pre>
<p><img src="optimizations/lazy/./../outputs/projection_pushdown/graph.png" alt="" /></p>
<p>Now were focussed on the projection's indicated with π. The first node shows π 3/6,
indicating that we select 3 out of 6 columns in the <code>DataFrame</code>. If we look the csv scans
we see a wildcard π */6 and π */1 meaning that we select all of 6 columns of the
reddit dataset and the one and only column from the runescape dataset respectively.</p>
<p>This query is not very optimal. We select all columns from both datasets and only show
3/6 after join. That means that there were some columns computed during the join
operation that could have been ignored. There were also columns parsed during csv
scanning only to be dropped at the end. When we are dealing with <code>DataFrame</code>s with a
large number of columns the redundant work that is done can be huge.</p>
<h3 id="optimized-query"><a class="header" href="#optimized-query">Optimized query</a></h3>
<p>Let's see how <code>Polars</code> optimizes this query.</p>
<pre><code class="language-python">dataset.show_graph(optimized=True)
</code></pre>
<p><img src="optimizations/lazy/./../outputs/projection_pushdown/graph-optimized.png" alt="" /></p>
<p>The projections are pushed down the join operation all the way to the csv scans. This
means that both the scanning and join operation have become cheaper due to the query
optimization.</p>
<h2 id="performance-2"><a class="header" href="#performance-2">Performance</a></h2>
<p>Let's time the result before and after optimization.</p>
<p><strong>Without optimization</strong>, <code>predicate_pushdown=False</code> and <code>projection_pushdown=False</code>.</p>
<pre><code class="language-text">real	0m3,273s
user	0m9,284s
sys	0m1,081s
</code></pre>
<p><strong>With optimization</strong>, <code>predicate_pushdown</code> and <code>projection_pushdown</code> flags both to
<code>True</code>.</p>
<pre><code class="language-text">real	0m1,732s
user	0m7,581s
sys	0m0,783s
</code></pre>
<p>We can see that we almost reduced query time by half on this simple query. With real
business data often comprising of many columns, filtering missing data, doing complex
groupby operations, and using joins we expect this difference between unoptimized queries and optimized
queries to only grow.</p>
<h1 id="other-optimizations"><a class="header" href="#other-optimizations">Other optimizations</a></h1>
<blockquote>
<p>The Other optimizations page is under construction.</p>
</blockquote>
<p>Besides predicate and projection pushdown, <code>Polars</code> does other optimizations.</p>
<p>One important topic is optional caching and parallelization. It's easy to imagine having two
different <code>DataFrame</code> computations that lead to a scan of the same file. <code>Polars</code> may cache
the scanned file to prevent scanning the same file twice. However, if you want to, you
may override this behavior and force <code>Polars</code> to read the same file. This could be faster
because the scan can be done in parallel.</p>
<h2 id="join-parallelization"><a class="header" href="#join-parallelization">Join parallelization</a></h2>
<p>If we look at the previous query, we see that the join operation has as input a
computation path with <code>data/reddit.csv</code> as root and one path with <code>data/runescape.csv</code>
as root. <code>Polars</code> can observe that there are no dependencies between the two <code>DataFrame</code>s and
will read both files in parallel. If other operations are done before the join (e.g.
groupby, filters, etc.) they are also executed in parallel.</p>
<p><img src="optimizations/lazy/../../outputs/projection_pushdown/graph-optimized.png" alt="" /></p>
<h2 id="simplify-expressions"><a class="header" href="#simplify-expressions">Simplify expressions</a></h2>
<p>Some other optimizations that are done are expression simplifications. The impact of
these optimizations is less than that of predicate and projection pushdown, but they
likely add up. You can
<a href="https://github.com/pola-rs/polars/issues/139">track this issue</a> to see the latest
status of those.</p>
<h1 id="reference-guide"><a class="header" href="#reference-guide">Reference guide</a></h1>
<p>Need to see all available methods/functions of <code>Polars</code>? We have <code>Rust</code> and <code>Python</code> references:</p>
<ul>
<li><a href="https://docs.rs/polars"><code>Rust</code> release</a></li>
<li><a href="https://pola-rs.github.io/polars/py-polars/html/reference"><code>Python</code> API</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
